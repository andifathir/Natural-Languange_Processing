{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80159ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data reduced and saved to 1000_rows_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def reduce_csv_to_1000_rows(input_csv, output_csv):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    # If the dataset has more than 1000 rows, randomly sample 1000 rows\n",
    "    if len(df) > 1000:\n",
    "        df_reduced = df.sample(n=1000, random_state=42)  # random_state for reproducibility\n",
    "    else:\n",
    "        df_reduced = df  # if there are fewer than 1000 rows, keep all rows\n",
    "\n",
    "    # Save the reduced dataset to a new CSV file\n",
    "    df_reduced.to_csv(output_csv, index=False)\n",
    "\n",
    "    print(f\"Data reduced and saved to {output_csv}\")\n",
    "\n",
    "# Example usage\n",
    "input_csv = 'cleaned_data.csv'  # Replace with your input CSV file path\n",
    "output_csv = '1000_rows_data.csv'  # Replace with your desired output file path\n",
    "reduce_csv_to_1000_rows(input_csv, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0bba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "df = pd.read_csv('reduced_output_file.csv')  # Replace 'your_file.csv' with your actual file path\n",
    "\n",
    "# Create DataFrame\n",
    "post_data = pd.DataFrame(df)\n",
    "\n",
    "# Step 1: Combine Title, Text, and Comments Data into separate rows\n",
    "\n",
    "# Convert Comments Data from string format to list\n",
    "post_data['Comments Data'] = post_data['Comments Data'].apply(ast.literal_eval)\n",
    "\n",
    "# Prepare the DataFrame for expanding to multiple rows\n",
    "expanded_data = []\n",
    "\n",
    "# Add the Title and Text as separate rows\n",
    "for _, row in post_data.iterrows():\n",
    "    # Add the title as a row\n",
    "    expanded_data.append({'Text': row['Title'], 'Category': 'No Slang', 'Date': datetime.fromtimestamp(row['Timestamp'], tz=timezone.utc).strftime('%Y-%m-%d %H:%M:%S'), 'Subreddit': row['Subreddit']})\n",
    "    \n",
    "    # Add the text (if available)\n",
    "    if row['Text']:\n",
    "        expanded_data.append({'Text': row['Text'], 'Category': 'No Slang', 'Date': datetime.fromtimestamp(row['Timestamp'], tz=timezone.utc).strftime('%Y-%m-%d %H:%M:%S'), 'Subreddit': row['Subreddit']})\n",
    "    \n",
    "    # Add each comment as a separate row\n",
    "    for comment in row['Comments Data']:\n",
    "        expanded_data.append({'Text': comment[0], 'Category': 'No Slang', 'Date': datetime.fromtimestamp(comment[2], tz=timezone.utc).strftime('%Y-%m-%d %H:%M:%S'), 'Subreddit': row['Subreddit']})\n",
    "\n",
    "# Create the expanded DataFrame\n",
    "expanded_df = pd.DataFrame(expanded_data)\n",
    "\n",
    "expanded_df.to_csv('cleaned_data.csv', index=False)  # Saves the cleaned data to a new file\n",
    "\n",
    "print(expanded_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c154410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Text       992 non-null    object\n",
      " 1   Category   1000 non-null   object\n",
      " 2   Date       1000 non-null   object\n",
      " 3   Subreddit  1000 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 31.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "                                                 Text  Category  \\\n",
       " 0  This man is a cut above the rest, outdoor or i...  No Slang   \n",
       " 1                                      Why not four?  No Slang   \n",
       " 2                                          MAGA baby  No Slang   \n",
       " 3  I doubt even ChatGPT would come up with a stor...  No Slang   \n",
       " 4  I feel that's kinda true but at the same time ...  No Slang   \n",
       " \n",
       "                   Date  Subreddit  \n",
       " 0  2025-03-18 12:36:49     soccer  \n",
       " 1  2025-03-15 16:30:40      funny  \n",
       " 2  2025-03-18 04:43:41  AskReddit  \n",
       " 3  2025-03-18 12:48:15     gaming  \n",
       " 4  2025-03-18 12:43:17     soccer  )"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"1000_rows_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display basic info and the first few rows\n",
    "df_info = df.info()\n",
    "df_head = df.head()\n",
    "\n",
    "df_info, df_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f88a87c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Cleaned_Text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Category_Label",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "Subreddit",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Subreddit_Label",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "Hour",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "DayOfWeek",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "Month",
         "rawType": "int32",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "6117f565-8b8c-4782-989f-07f3786275ee",
       "rows": [
        [
         "0",
         "this man is a cut above the rest outdoor or inside",
         "No Slang",
         "0",
         "soccer",
         "6",
         "12",
         "1",
         "3"
        ],
        [
         "1",
         "why not four",
         "No Slang",
         "0",
         "funny",
         "3",
         "16",
         "5",
         "3"
        ],
        [
         "2",
         "maga baby",
         "No Slang",
         "0",
         "AskReddit",
         "0",
         "4",
         "1",
         "3"
        ],
        [
         "3",
         "i doubt even chatgpt would come up with a story as stupid as a bunch of hipsters that become criminals and killers in order to pay off their student loans",
         "No Slang",
         "0",
         "gaming",
         "4",
         "12",
         "1",
         "3"
        ],
        [
         "4",
         "i feel thats kinda true but at the same time also not true smaller teams also can benefit extremly for that rulechange because they play intense football and have more subs for that sure city can bring in more worldclass players but as a smaller team more fit players can already help a lot",
         "No Slang",
         "0",
         "soccer",
         "6",
         "12",
         "1",
         "3"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>Category_Label</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Subreddit_Label</th>\n",
       "      <th>Hour</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this man is a cut above the rest outdoor or in...</td>\n",
       "      <td>No Slang</td>\n",
       "      <td>0</td>\n",
       "      <td>soccer</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why not four</td>\n",
       "      <td>No Slang</td>\n",
       "      <td>0</td>\n",
       "      <td>funny</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maga baby</td>\n",
       "      <td>No Slang</td>\n",
       "      <td>0</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i doubt even chatgpt would come up with a stor...</td>\n",
       "      <td>No Slang</td>\n",
       "      <td>0</td>\n",
       "      <td>gaming</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i feel thats kinda true but at the same time a...</td>\n",
       "      <td>No Slang</td>\n",
       "      <td>0</td>\n",
       "      <td>soccer</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Cleaned_Text  Category  \\\n",
       "0  this man is a cut above the rest outdoor or in...  No Slang   \n",
       "1                                       why not four  No Slang   \n",
       "2                                          maga baby  No Slang   \n",
       "3  i doubt even chatgpt would come up with a stor...  No Slang   \n",
       "4  i feel thats kinda true but at the same time a...  No Slang   \n",
       "\n",
       "   Category_Label  Subreddit  Subreddit_Label  Hour  DayOfWeek  Month  \n",
       "0               0     soccer                6    12          1      3  \n",
       "1               0      funny                3    16          5      3  \n",
       "2               0  AskReddit                0     4          1      3  \n",
       "3               0     gaming                4    12          1      3  \n",
       "4               0     soccer                6    12          1      3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Salin dataframe untuk diolah\n",
    "df_cleaned = df.copy()\n",
    "\n",
    "# --- Step 1: Data Cleaning ---\n",
    "# Hapus baris dengan Text yang kosong\n",
    "df_cleaned = df_cleaned.dropna(subset=['Text'])\n",
    "\n",
    "# Hapus duplikat (jika ada)\n",
    "df_cleaned = df_cleaned.drop_duplicates()\n",
    "\n",
    "# Hapus URL, simbol aneh, dan lowercase\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)  # hapus URL\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)  # hapus semua non-huruf\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # hapus spasi berlebih\n",
    "    return text\n",
    "\n",
    "df_cleaned[\"Cleaned_Text\"] = df_cleaned[\"Text\"].apply(clean_text)\n",
    "\n",
    "# --- Step 2: Data Transformation ---\n",
    "# Ubah kolom Date ke datetime\n",
    "df_cleaned[\"Date\"] = pd.to_datetime(df_cleaned[\"Date\"], errors=\"coerce\")\n",
    "\n",
    "# Tambah fitur dari kolom Date\n",
    "df_cleaned[\"Hour\"] = df_cleaned[\"Date\"].dt.hour\n",
    "df_cleaned[\"DayOfWeek\"] = df_cleaned[\"Date\"].dt.dayofweek\n",
    "df_cleaned[\"Month\"] = df_cleaned[\"Date\"].dt.month\n",
    "\n",
    "# --- Step 3: Encoding untuk klasifikasi nanti ---\n",
    "# Label encoding kategori dan subreddit\n",
    "df_cleaned[\"Category_Label\"] = df_cleaned[\"Category\"].astype(\"category\").cat.codes\n",
    "df_cleaned[\"Subreddit_Label\"] = df_cleaned[\"Subreddit\"].astype(\"category\").cat.codes\n",
    "\n",
    "# Tampilkan hasil akhir sebagian\n",
    "df_cleaned[[\"Cleaned_Text\", \"Category\", \"Category_Label\", \"Subreddit\", \"Subreddit_Label\", \"Hour\", \"DayOfWeek\", \"Month\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ccbe602",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# --- Step 4: Text Vectorization (TF-IDF) ---\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Gunakan TF-IDF pada Cleaned_Text\u001b[39;00m\n\u001b[0;32m      5\u001b[0m tfidf_vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer(\n\u001b[0;32m      6\u001b[0m     max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,  \u001b[38;5;66;03m# ambil 1000 kata paling penting\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# hilangkan stop words\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     ngram_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# unigram dan bigram\u001b[39;00m\n\u001b[0;32m      9\u001b[0m )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# --- Step 4: Text Vectorization (TF-IDF) ---\n",
    "# Gunakan TF-IDF pada Cleaned_Text\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=1000,  # ambil 1000 kata paling penting\n",
    "    stop_words='english',  # hilangkan stop words\n",
    "    ngram_range=(1, 2)  # unigram dan bigram\n",
    ")\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df_cleaned[\"Cleaned_Text\"])\n",
    "\n",
    "# Bentuk dari hasil TF-IDF\n",
    "tfidf_matrix.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
