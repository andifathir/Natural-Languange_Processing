{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce365b45",
   "metadata": {},
   "source": [
    "## Data Integration merge all text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34dfbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "df = pd.read_csv('Original Data.csv')  # Replace 'your_file.csv' with your actual file path\n",
    "\n",
    "# Create DataFrame\n",
    "post_data = pd.DataFrame(df)\n",
    "\n",
    "# Step 1: Combine Title, Text, and Comments Data into separate rows\n",
    "\n",
    "# Convert Comments Data from string format to list\n",
    "post_data['Comments Data'] = post_data['Comments Data'].apply(ast.literal_eval)\n",
    "\n",
    "# Prepare the DataFrame for expanding to multiple rows\n",
    "expanded_data = []\n",
    "\n",
    "# Add the Title and Text as separate rows\n",
    "for _, row in post_data.iterrows():\n",
    "    # Add the title as a row\n",
    "    expanded_data.append({'Text': row['Title'], 'Category': 'No Slang', 'Date': datetime.fromtimestamp(row['Timestamp'], tz=timezone.utc).strftime('%Y-%m-%d %H:%M:%S'), 'Upvotes': row['Upvotes'], 'Subreddit': row['Subreddit']})\n",
    "    \n",
    "    # Add the text (if available)\n",
    "    if row['Text']:\n",
    "        expanded_data.append({'Text': row['Text'], 'Category': 'No Slang', 'Date': datetime.fromtimestamp(row['Timestamp'], tz=timezone.utc).strftime('%Y-%m-%d %H:%M:%S'), 'Upvotes': row['Upvotes'], 'Subreddit': row['Subreddit']})\n",
    "    \n",
    "    # Add each comment as a separate row\n",
    "    for comment in row['Comments Data']:\n",
    "        expanded_data.append({'Text': comment[0], 'Category': 'No Slang', 'Date': datetime.fromtimestamp(comment[2], tz=timezone.utc).strftime('%Y-%m-%d %H:%M:%S'), 'Upvotes': comment[1], 'Subreddit': row['Subreddit']})\n",
    "\n",
    "# Create the expanded DataFrame\n",
    "expanded_df = pd.DataFrame(expanded_data)\n",
    "\n",
    "expanded_df.to_csv('merge_all_text.csv', index=False)  # Saves the cleaned data to a new file\n",
    "\n",
    "print(expanded_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096145ca",
   "metadata": {},
   "source": [
    "## Reduce rows from 100000 to 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bb663f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data reduced and saved to reduced_output.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def reduce_csv_to_1000_rows(input_csv, output_csv):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    # If the dataset has more than 1000 rows, randomly sample 1000 rows\n",
    "    if len(df) > 1000:\n",
    "        df_reduced = df.sample(n=7100, random_state=42)  # random_state for reproducibility\n",
    "    else:\n",
    "        df_reduced = df  # if there are fewer than 1000 rows, keep all rows\n",
    "\n",
    "    # Save the reduced dataset to a new CSV file\n",
    "    df_reduced[[\"Text\", \"Subreddit\", \"Category\"]].to_csv(output_csv, index=False)\n",
    "\n",
    "    print(f\"Data reduced and saved to {output_csv}\")\n",
    "\n",
    "# Example usage\n",
    "input_csv = 'C:/personal/Code/S6/NLP/Slang Classification/Datas/merge_all_text.csv'  # Replace with your input CSV file path\n",
    "output_csv = 'reduced_output.csv'  # Replace with your desired output file path\n",
    "reduce_csv_to_1000_rows(input_csv, output_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b43d3a",
   "metadata": {},
   "source": [
    "# Reduce again for labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88449c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6092f420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Text       9939 non-null   object\n",
      " 1   Subreddit  10000 non-null  object\n",
      " 2   Category   10000 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 234.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = 'reduced_output_10000.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "text_column = 'Text'  # Replace with the actual column name containing text\n",
    "label_column = 'Category'  # Replace with the actual label column name\n",
    "\n",
    "# Show the first few rows of the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3386fec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Text'])\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b66fc6",
   "metadata": {},
   "source": [
    "## Cleaning data for labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec7fbea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Case Folding\n",
    "def case_folding(text):\n",
    "    if isinstance(text, str):  # Check if the value is a string\n",
    "        return text.lower()\n",
    "    else:\n",
    "        return \"\"  # Return an empty string for non-string values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29b6265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Cleaning (remove unwanted characters)\n",
    "def clean_text(text):\n",
    "    # Remove HTML tags, URLs, mentions (@user), hashtags (#), emojis, digits, and punctuation\n",
    "    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text)  # Remove mentions\n",
    "    text = re.sub(r'#\\w+', '', text)  # Remove hashtags\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove digits\n",
    "    text = re.sub(r'[\\U00010000-\\U0010ffff]', '', text)  # Remove emojis\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)  # hapus URL\n",
    "    # text = re.sub(r\"[^a-z\\s]\", \"\", text)  # hapus semua non-huruf\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # hapus spasi berlebih\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "084fc8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply all steps to the dataset\n",
    "def preprocess_text(text):\n",
    "    text = case_folding(text)  # Step 1: Case folding\n",
    "    text = clean_text(text)  # Step 2: Data cleaning\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce8334e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to each row in the dataset\n",
    "df['Text'] = df[text_column].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea720412",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(n=2000, random_state=42)  # random_state for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d55a5fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Text\", \"Subreddit\", \"Category\"]].to_csv('ready_for_labelling.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ad3aeb",
   "metadata": {},
   "source": [
    "# Dataset Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88e98820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efb55805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Subreddit",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Category",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "ba9666b2-8094-4c97-8d32-b533c36b2f03",
       "rows": [
        [
         "0",
         "im someone who takes long showers too and i never thought of it as weird until my mom started asking me questions in reality i just like using my phone in the shower i live in a pretty warm country and use that to cool down while still browsing my phone lmao",
         "funny",
         "Internet Slang"
        ],
        [
         "1",
         "look up the sankebetsu brown bear incident",
         "NoStupidQuestions",
         "No Slang"
        ],
        [
         "2",
         "this is all i know about the british and something about crumpets",
         "memes",
         "No Slang"
        ],
        [
         "3",
         "and a bunch of people put down k deposits for vaporware",
         "OutOfTheLoop",
         "Casual Slang"
        ],
        [
         "4",
         "wade boggs gone too soon",
         "AskReddit",
         "No Slang"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im someone who takes long showers too and i ne...</td>\n",
       "      <td>funny</td>\n",
       "      <td>Internet Slang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>look up the sankebetsu brown bear incident</td>\n",
       "      <td>NoStupidQuestions</td>\n",
       "      <td>No Slang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this is all i know about the british and somet...</td>\n",
       "      <td>memes</td>\n",
       "      <td>No Slang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and a bunch of people put down k deposits for ...</td>\n",
       "      <td>OutOfTheLoop</td>\n",
       "      <td>Casual Slang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wade boggs gone too soon</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>No Slang</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text          Subreddit  \\\n",
       "0  im someone who takes long showers too and i ne...              funny   \n",
       "1         look up the sankebetsu brown bear incident  NoStupidQuestions   \n",
       "2  this is all i know about the british and somet...              memes   \n",
       "3  and a bunch of people put down k deposits for ...       OutOfTheLoop   \n",
       "4                           wade boggs gone too soon          AskReddit   \n",
       "\n",
       "         Category  \n",
       "0  Internet Slang  \n",
       "1        No Slang  \n",
       "2        No Slang  \n",
       "3    Casual Slang  \n",
       "4        No Slang  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = 'ready_for_labelling - ready_for_labelling.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "text_column = 'Text'  # Replace with the actual column name containing text\n",
    "label_column = 'Category'  # Replace with the actual label column name\n",
    "\n",
    "# Show the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4690db6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\andif\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\andif\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the stemmer and lemmatizer\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f670275",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "705a73d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Text'])\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f73f82f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Case Folding\n",
    "def case_folding(text):\n",
    "    if isinstance(text, str):  # Check if the value is a string\n",
    "        return text.lower()\n",
    "    else:\n",
    "        return \"\"  # Return an empty string for non-string values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e8dfcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Cleaning (remove unwanted characters)\n",
    "def clean_text(text):\n",
    "    # Remove HTML tags, URLs, mentions (@user), hashtags (#), emojis, digits, and punctuation\n",
    "    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text)  # Remove mentions\n",
    "    text = re.sub(r'#\\w+', '', text)  # Remove hashtags\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove digits\n",
    "    text = re.sub(r'[\\U00010000-\\U0010ffff]', '', text)  # Remove emojis\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe8c46ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Tokenization\n",
    "def tokenize(text):\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "553f49bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Stopwords Removal\n",
    "def remove_stopwords(tokens):\n",
    "    stop_words = set(stopwords.words('english'))  # Change to 'english' for English stopwords\n",
    "    return [word for word in tokens if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10b033b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Stemming and Lemmatization\n",
    "def stem_and_lemmatize(tokens, use_stemming=True):\n",
    "    if use_stemming:\n",
    "        return [stemmer.stem(word) for word in tokens]\n",
    "    else:\n",
    "        return [lemmatizer.lemmatize(word) for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df1c2e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Manual Padding/Truncating\n",
    "def padding_truncating(tokens, max_len=100):\n",
    "    # If the sequence is shorter than max_len, pad with 'PAD' tokens\n",
    "    if len(tokens) < max_len:\n",
    "        tokens += ['PAD'] * (max_len - len(tokens))\n",
    "    # If the sequence is longer than max_len, truncate it\n",
    "    elif len(tokens) > max_len:\n",
    "        tokens = tokens[:max_len]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acb3b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply all steps to the dataset\n",
    "def preprocess_text(text, use_stemming=True):\n",
    "    text = case_folding(text)  # Step 1: Case folding\n",
    "    text = clean_text(text)  # Step 2: Data cleaning\n",
    "    tokens = tokenize(text)  # Step 3: Tokenization\n",
    "    tokens = remove_stopwords(tokens)  # Step 4: Stopwords removal\n",
    "    tokens = stem_and_lemmatize(tokens, use_stemming)  # Step 5: Stemming/Lemmatization\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f98a519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to each row in the dataset\n",
    "df['processed_text'] = df[text_column].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffaf16e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Padding/Truncating and Text-to-Numeric Transformation\n",
    "# Assuming 'processed_text' column contains tokenized text\n",
    "df['padded_text'] = df['processed_text'].apply(lambda x: padding_truncating(x, max_len=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36b4839e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Category  Category_Label\n",
      "0  Internet Slang             1.0\n",
      "1        No Slang             3.0\n",
      "2        No Slang             3.0\n",
      "3    Casual Slang             0.0\n",
      "4        No Slang             3.0\n",
      "5    Casual Slang             0.0\n",
      "6        No Slang             3.0\n",
      "7        No Slang             3.0\n",
      "8        No Slang             3.0\n",
      "9        No Slang             3.0\n"
     ]
    }
   ],
   "source": [
    "# Define a custom mapping for categories\n",
    "category_mapping = {\n",
    "    \"Casual Slang\": 0,\n",
    "    \"Internet Slang\": 1,\n",
    "    \"Offensive Slang\": 2,\n",
    "    \"No Slang\": 3\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'Category' column\n",
    "df[\"Category_Label\"] = df[\"Category\"].map(category_mapping)\n",
    "\n",
    "# Check the results\n",
    "print(df[[\"Category\", \"Category_Label\"]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb572a7",
   "metadata": {},
   "source": [
    "# Vectorize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd96750a",
   "metadata": {},
   "source": [
    "# Models Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "731eddac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f606218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n",
    "    if train:\n",
    "        pred = clf.predict(X_train)\n",
    "        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        pred = clf.predict(X_test)\n",
    "        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c270fc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = df.dropna(subset=['padded_text', 'Category_Label'])\n",
    "\n",
    "X = df['padded_text'].apply(lambda x: ' '.join(x))  # Join tokens back into text for TF-IDF\n",
    "y = df['Category_Label']  # The encoded label column\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 1. Text Vectorization using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Set max features to limit the number of tokens\n",
    "X_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d019947",
   "metadata": {},
   "source": [
    "## Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "af2c7418",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['processed_text', 'Category_Label'])\n",
    "X = df['processed_text'].apply(lambda x: ' '.join(x))  # Use plain text for BERT\n",
    "y = df['Category_Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Pass X_train and X_test (still strings) directly to the BERT dataset class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9ad19bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1: 100%|██████████| 22/22 [02:25<00:00,  6.59s/it, loss=1.15] \n",
      "Epoch 2: 100%|██████████| 22/22 [02:24<00:00,  6.59s/it, loss=1.21] \n",
      "Epoch 3: 100%|██████████| 22/22 [02:24<00:00,  6.59s/it, loss=0.807]\n",
      "Epoch 4: 100%|██████████| 22/22 [02:23<00:00,  6.53s/it, loss=0.789]\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.6414, F1: 0.5013, Precision: 0.4114, Recall: 0.6414\n",
      "Test Accuracy:   0.7027, F1: 0.5800, Precision: 0.4938, Recall: 0.7027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, get_scheduler\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# 1. Tokenizer & Model\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=len(y.unique()))\n",
    "\n",
    "# 2. Dataset\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = int(self.labels[idx])\n",
    "        encoding = self.tokenizer(text,\n",
    "                                  truncation=True,\n",
    "                                  padding='max_length',\n",
    "                                  max_length=self.max_len,\n",
    "                                  return_tensors='pt')\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# 3. Prepare DataLoaders\n",
    "train_dataset = TextDataset(X_train.tolist(), y_train.tolist(), tokenizer)\n",
    "test_dataset = TextDataset(X_test.tolist(), y_test.tolist(), tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "# 4. Training Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "num_epochs = 4\n",
    "total_steps = len(train_loader) * num_epochs\n",
    "\n",
    "lr_scheduler = get_scheduler(\"linear\",\n",
    "                             optimizer=optimizer,\n",
    "                             num_warmup_steps=0,\n",
    "                             num_training_steps=total_steps)\n",
    "\n",
    "# 5. Training Loop\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "    for batch in loop:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "# 6. Evaluation\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    prec = precision_score(all_labels, all_preds, average='weighted')\n",
    "    rec = recall_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    return acc, f1, prec, rec\n",
    "\n",
    "train_metrics = evaluate(train_loader)\n",
    "test_metrics = evaluate(test_loader)\n",
    "\n",
    "print(f\"Train Accuracy:  {train_metrics[0]:.4f}, F1: {train_metrics[1]:.4f}, Precision: {train_metrics[2]:.4f}, Recall: {train_metrics[3]:.4f}\")\n",
    "print(f\"Test Accuracy:   {test_metrics[0]:.4f}, F1: {test_metrics[1]:.4f}, Precision: {test_metrics[2]:.4f}, Recall: {test_metrics[3]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b66c50",
   "metadata": {},
   "source": [
    "# 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "34ec3236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 64.80%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "              0     1     2           3  accuracy   macro avg  weighted avg\n",
      "precision   0.0   0.0   0.0    0.647959  0.647959    0.161990      0.419851\n",
      "recall      0.0   0.0   0.0    1.000000  0.647959    0.250000      0.647959\n",
      "f1-score    0.0   0.0   0.0    0.786378  0.647959    0.196594      0.509541\n",
      "support    43.0  71.0  24.0  254.000000  0.647959  392.000000    392.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[  0   0   0  43]\n",
      " [  0   0   0  71]\n",
      " [  0   0   0  24]\n",
      " [  0   0   0 254]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 70.71%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "             0     1    2          3  accuracy  macro avg  weighted avg\n",
      "precision  0.0   0.0  0.0   0.707071  0.707071   0.176768      0.499949\n",
      "recall     0.0   0.0  0.0   1.000000  0.707071   0.250000      0.707071\n",
      "f1-score   0.0   0.0  0.0   0.828402  0.707071   0.207101      0.585739\n",
      "support    6.0  16.0  7.0  70.000000  0.707071  99.000000     99.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[ 0  0  0  6]\n",
      " [ 0  0  0 16]\n",
      " [ 0  0  0  7]\n",
      " [ 0  0  0 70]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(lr_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(lr_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0ca4310d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Training Accuracy %",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Testing Accuracy %",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "8daf3d7b-c5fb-4588-a251-825d58682122",
       "rows": [
        [
         "0",
         "Logistic Regression",
         "64.79591836734694",
         "70.70707070707071"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy %</th>\n",
       "      <th>Testing Accuracy %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>64.795918</td>\n",
       "      <td>70.707071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Training Accuracy %  Testing Accuracy %\n",
       "0  Logistic Regression            64.795918           70.707071"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = accuracy_score(y_test, lr_clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, lr_clf.predict(X_train)) * 100\n",
    "\n",
    "results_df = pd.DataFrame(data=[[\"Logistic Regression\", train_score, test_score]], columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a018a7b",
   "metadata": {},
   "source": [
    "# 2. K-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "65fc3dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 65.31%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                 0.0        1.0        2.0         3.0  accuracy   macro avg  \\\n",
      "precision   1.000000   1.000000   0.666667    0.649852  0.653061    0.829130   \n",
      "recall      0.026316   0.031250   0.095238    0.995455  0.653061    0.287065   \n",
      "f1-score    0.051282   0.060606   0.166667    0.786355  0.653061    0.266228   \n",
      "support    38.000000  64.000000  21.000000  220.000000  0.653061  343.000000   \n",
      "\n",
      "           weighted avg  \n",
      "precision      0.755007  \n",
      "recall         0.653061  \n",
      "f1-score       0.531562  \n",
      "support      343.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[  1   0   0  37]\n",
      " [  0   2   0  62]\n",
      " [  0   0   2  19]\n",
      " [  0   0   1 219]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 69.59%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "            0.0   1.0   2.0         3.0  accuracy   macro avg  weighted avg\n",
      "precision   0.0   0.0   0.0    0.700680  0.695946    0.175170      0.492370\n",
      "recall      0.0   0.0   0.0    0.990385  0.695946    0.247596      0.695946\n",
      "f1-score    0.0   0.0   0.0    0.820717  0.695946    0.205179      0.576720\n",
      "support    11.0  23.0  10.0  104.000000  0.695946  148.000000    148.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[  0   0   0  11]\n",
      " [  0   0   0  23]\n",
      " [  0   0   0  10]\n",
      " [  1   0   0 103]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(knn_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(knn_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "14b1d93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Training Accuracy %",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Testing Accuracy %",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "8ce7f468-11e7-4f57-ac10-422cba54db91",
       "rows": [
        [
         "0",
         "Logistic Regression",
         "64.1399416909621",
         "70.27027027027027"
        ],
        [
         "1",
         "K-nearest neighbors",
         "65.3061224489796",
         "69.5945945945946"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy %</th>\n",
       "      <th>Testing Accuracy %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>64.139942</td>\n",
       "      <td>70.270270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-nearest neighbors</td>\n",
       "      <td>65.306122</td>\n",
       "      <td>69.594595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Training Accuracy %  Testing Accuracy %\n",
       "0  Logistic Regression            64.139942           70.270270\n",
       "1  K-nearest neighbors            65.306122           69.594595"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = accuracy_score(y_test, knn_clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, knn_clf.predict(X_train)) * 100\n",
    "\n",
    "results_df_2 = pd.DataFrame(data=[[\"K-nearest neighbors\", train_score, test_score]], \n",
    "                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\n",
    "results_df = pd.concat([results_df, results_df_2], ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f897a97c",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "026a241a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 64.14%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "            0.0   1.0   2.0         3.0  accuracy   macro avg  weighted avg\n",
      "precision   0.0   0.0   0.0    0.641399  0.641399    0.160350      0.411393\n",
      "recall      0.0   0.0   0.0    1.000000  0.641399    0.250000      0.641399\n",
      "f1-score    0.0   0.0   0.0    0.781528  0.641399    0.195382      0.501271\n",
      "support    38.0  64.0  21.0  220.000000  0.641399  343.000000    343.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[  0   0   0  38]\n",
      " [  0   0   0  64]\n",
      " [  0   0   0  21]\n",
      " [  0   0   0 220]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 70.27%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "            0.0   1.0   2.0         3.0  accuracy   macro avg  weighted avg\n",
      "precision   0.0   0.0   0.0    0.702703  0.702703    0.175676      0.493791\n",
      "recall      0.0   0.0   0.0    1.000000  0.702703    0.250000      0.702703\n",
      "f1-score    0.0   0.0   0.0    0.825397  0.702703    0.206349      0.580009\n",
      "support    11.0  23.0  10.0  104.000000  0.702703  148.000000    148.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[  0   0   0  11]\n",
      " [  0   0   0  23]\n",
      " [  0   0   0  10]\n",
      " [  0   0   0 104]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "svm_clf = SVC(kernel='rbf', gamma=0.1, C=1.0)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(svm_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(svm_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4611f20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Training Accuracy %",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Testing Accuracy %",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "ebb6dd69-3374-4d5d-9109-4d8f18e82daf",
       "rows": [
        [
         "0",
         "Logistic Regression",
         "64.1399416909621",
         "70.27027027027027"
        ],
        [
         "1",
         "K-nearest neighbors",
         "65.3061224489796",
         "69.5945945945946"
        ],
        [
         "2",
         "Support Vector Machine",
         "64.1399416909621",
         "70.27027027027027"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy %</th>\n",
       "      <th>Testing Accuracy %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>64.139942</td>\n",
       "      <td>70.270270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-nearest neighbors</td>\n",
       "      <td>65.306122</td>\n",
       "      <td>69.594595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>64.139942</td>\n",
       "      <td>70.270270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Training Accuracy %  Testing Accuracy %\n",
       "0     Logistic Regression            64.139942           70.270270\n",
       "1     K-nearest neighbors            65.306122           69.594595\n",
       "2  Support Vector Machine            64.139942           70.270270"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = accuracy_score(y_test, svm_clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, svm_clf.predict(X_train)) * 100\n",
    "\n",
    "results_df_2 = pd.DataFrame(data=[[\"Support Vector Machine\", train_score, test_score]], \n",
    "                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\n",
    "results_df = pd.concat([results_df, results_df_2], ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1163fa03",
   "metadata": {},
   "source": [
    "# 4. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c54c0fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 100.00%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "              0     1     2      3  accuracy  macro avg  weighted avg\n",
      "precision   1.0   1.0   1.0    1.0       1.0        1.0           1.0\n",
      "recall      1.0   1.0   1.0    1.0       1.0        1.0           1.0\n",
      "f1-score    1.0   1.0   1.0    1.0       1.0        1.0           1.0\n",
      "support    43.0  71.0  24.0  254.0       1.0      392.0         392.0\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[ 43   0   0   0]\n",
      " [  0  71   0   0]\n",
      " [  0   0  24   0]\n",
      " [  0   0   0 254]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 68.69%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                  0          1         2          3  accuracy  macro avg  \\\n",
      "precision  0.166667   0.500000  0.666667   0.756410  0.686869   0.522436   \n",
      "recall     0.166667   0.375000  0.285714   0.842857  0.686869   0.417560   \n",
      "f1-score   0.166667   0.428571  0.400000   0.797297  0.686869   0.448134   \n",
      "support    6.000000  16.000000  7.000000  70.000000  0.686869  99.000000   \n",
      "\n",
      "           weighted avg  \n",
      "precision      0.672883  \n",
      "recall         0.686869  \n",
      "f1-score       0.671393  \n",
      "support       99.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[ 1  0  0  5]\n",
      " [ 0  6  1  9]\n",
      " [ 0  0  2  5]\n",
      " [ 5  6  0 59]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(tree_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(tree_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ed1d7218",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[103]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m train_score = accuracy_score(y_train, tree_clf.predict(X_train)) * \u001b[32m100\u001b[39m\n\u001b[32m      4\u001b[39m results_df_2 = pd.DataFrame(data=[[\u001b[33m\"\u001b[39m\u001b[33mDecision Tree Classifier\u001b[39m\u001b[33m\"\u001b[39m, train_score, test_score]], \n\u001b[32m      5\u001b[39m                           columns=[\u001b[33m'\u001b[39m\u001b[33mModel\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mTraining Accuracy \u001b[39m\u001b[33m%\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mTesting Accuracy \u001b[39m\u001b[33m%\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m results_df = pd.concat([\u001b[43mresults_df\u001b[49m, results_df_2], ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      7\u001b[39m results_df\n",
      "\u001b[31mNameError\u001b[39m: name 'results_df' is not defined"
     ]
    }
   ],
   "source": [
    "test_score = accuracy_score(y_test, tree_clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, tree_clf.predict(X_train)) * 100\n",
    "\n",
    "results_df_2 = pd.DataFrame(data=[[\"Decision Tree Classifier\", train_score, test_score]], \n",
    "                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\n",
    "results_df = pd.concat([results_df, results_df_2], ignore_index=True)\n",
    "results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7964396f",
   "metadata": {},
   "source": [
    "#  5. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b548bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         6\n",
      "         1.0       1.00      0.19      0.32        16\n",
      "         2.0       1.00      0.14      0.25         7\n",
      "         3.0       0.74      1.00      0.85        70\n",
      "\n",
      "    accuracy                           0.75        99\n",
      "   macro avg       0.68      0.33      0.35        99\n",
      "weighted avg       0.75      0.75      0.67        99\n",
      "\n",
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 100.00%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "            0.0   1.0   2.0    3.0  accuracy  macro avg  weighted avg\n",
      "precision   1.0   1.0   1.0    1.0       1.0        1.0           1.0\n",
      "recall      1.0   1.0   1.0    1.0       1.0        1.0           1.0\n",
      "f1-score    1.0   1.0   1.0    1.0       1.0        1.0           1.0\n",
      "support    43.0  71.0  24.0  254.0       1.0      392.0         392.0\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[ 43   0   0   0]\n",
      " [  0  71   0   0]\n",
      " [  0   0  24   0]\n",
      " [  0   0   0 254]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 74.75%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "           0.0        1.0       2.0        3.0  accuracy  macro avg  \\\n",
      "precision  0.0   1.000000  1.000000   0.736842  0.747475   0.684211   \n",
      "recall     0.0   0.187500  0.142857   1.000000  0.747475   0.332589   \n",
      "f1-score   0.0   0.315789  0.250000   0.848485  0.747475   0.353569   \n",
      "support    6.0  16.000000  7.000000  70.000000  0.747475  99.000000   \n",
      "\n",
      "           weighted avg  \n",
      "precision      0.753323  \n",
      "recall         0.747475  \n",
      "f1-score       0.668652  \n",
      "support       99.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[ 0  0  0  6]\n",
      " [ 0  3  0 13]\n",
      " [ 0  0  1  6]\n",
      " [ 0  0  0 70]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2e27369a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Training Accuracy %",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Testing Accuracy %",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "452dd10d-9bba-459b-9ecf-c4f87c9e8742",
       "rows": [
        [
         "0",
         "Logistic Regression",
         "64.1399416909621",
         "70.27027027027027"
        ],
        [
         "1",
         "K-nearest neighbors",
         "65.3061224489796",
         "69.5945945945946"
        ],
        [
         "2",
         "Support Vector Machine",
         "64.1399416909621",
         "70.27027027027027"
        ],
        [
         "3",
         "Decision Tree Classifier",
         "100.0",
         "59.45945945945946"
        ],
        [
         "4",
         "Random Forest Classifier",
         "100.0",
         "72.97297297297297"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy %</th>\n",
       "      <th>Testing Accuracy %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>64.139942</td>\n",
       "      <td>70.270270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-nearest neighbors</td>\n",
       "      <td>65.306122</td>\n",
       "      <td>69.594595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>64.139942</td>\n",
       "      <td>70.270270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>59.459459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>72.972973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  Training Accuracy %  Testing Accuracy %\n",
       "0       Logistic Regression            64.139942           70.270270\n",
       "1       K-nearest neighbors            65.306122           69.594595\n",
       "2    Support Vector Machine            64.139942           70.270270\n",
       "3  Decision Tree Classifier           100.000000           59.459459\n",
       "4  Random Forest Classifier           100.000000           72.972973"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = accuracy_score(y_test, rf_clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, rf_clf.predict(X_train)) * 100\n",
    "\n",
    "results_df_2 = pd.DataFrame(data=[[\"Random Forest Classifier\", train_score, test_score]], \n",
    "                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\n",
    "results_df = pd.concat([results_df, results_df_2], ignore_index=True)\n",
    "results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c953791",
   "metadata": {},
   "source": [
    "# 6. XGBoost Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "810db141",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [01:04:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 98.83%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                 0.0        1.0   2.0         3.0  accuracy   macro avg  \\\n",
      "precision   1.000000   1.000000   1.0    0.982143  0.988338    0.995536   \n",
      "recall      0.973684   0.953125   1.0    1.000000  0.988338    0.981702   \n",
      "f1-score    0.986667   0.976000   1.0    0.990991  0.988338    0.988414   \n",
      "support    38.000000  64.000000  21.0  220.000000  0.988338  343.000000   \n",
      "\n",
      "           weighted avg  \n",
      "precision      0.988546  \n",
      "recall         0.988338  \n",
      "f1-score       0.988266  \n",
      "support      343.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[ 37   0   0   1]\n",
      " [  0  61   0   3]\n",
      " [  0   0  21   0]\n",
      " [  0   0   0 220]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 63.51%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                 0.0        1.0        2.0         3.0  accuracy   macro avg  \\\n",
      "precision   0.125000   0.230769   0.500000    0.712000  0.635135    0.391942   \n",
      "recall      0.090909   0.130435   0.100000    0.855769  0.635135    0.294278   \n",
      "f1-score    0.105263   0.166667   0.166667    0.777293  0.635135    0.303972   \n",
      "support    11.000000  23.000000  10.000000  104.000000  0.635135  148.000000   \n",
      "\n",
      "           weighted avg  \n",
      "precision      0.579261  \n",
      "recall         0.635135  \n",
      "f1-score       0.591191  \n",
      "support      148.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[ 1  0  0 10]\n",
      " [ 3  3  0 17]\n",
      " [ 0  0  1  9]\n",
      " [ 4 10  1 89]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_clf = XGBClassifier(use_label_encoder=False)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(xgb_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(xgb_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "06a541c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Training Accuracy %",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Testing Accuracy %",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "0b54de7b-9beb-4cf8-87f9-106fee89b921",
       "rows": [
        [
         "0",
         "Logistic Regression",
         "64.1399416909621",
         "70.27027027027027"
        ],
        [
         "1",
         "K-nearest neighbors",
         "65.3061224489796",
         "69.5945945945946"
        ],
        [
         "2",
         "Support Vector Machine",
         "64.1399416909621",
         "70.27027027027027"
        ],
        [
         "3",
         "Decision Tree Classifier",
         "100.0",
         "59.45945945945946"
        ],
        [
         "4",
         "Random Forest Classifier",
         "100.0",
         "72.97297297297297"
        ],
        [
         "5",
         "XGBoost Classifier",
         "98.83381924198251",
         "63.51351351351351"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy %</th>\n",
       "      <th>Testing Accuracy %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>64.139942</td>\n",
       "      <td>70.270270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-nearest neighbors</td>\n",
       "      <td>65.306122</td>\n",
       "      <td>69.594595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>64.139942</td>\n",
       "      <td>70.270270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>59.459459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>72.972973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>98.833819</td>\n",
       "      <td>63.513514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  Training Accuracy %  Testing Accuracy %\n",
       "0       Logistic Regression            64.139942           70.270270\n",
       "1       K-nearest neighbors            65.306122           69.594595\n",
       "2    Support Vector Machine            64.139942           70.270270\n",
       "3  Decision Tree Classifier           100.000000           59.459459\n",
       "4  Random Forest Classifier           100.000000           72.972973\n",
       "5        XGBoost Classifier            98.833819           63.513514"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = accuracy_score(y_test, xgb_clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, xgb_clf.predict(X_train)) * 100\n",
    "\n",
    "results_df_2 = pd.DataFrame(data=[[\"XGBoost Classifier\", train_score, test_score]], \n",
    "                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\n",
    "results_df = pd.concat([results_df, results_df_2], ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca2209b",
   "metadata": {},
   "source": [
    "# 🤖 Models Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "673e6091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best parameters: {'C': 0.0001, 'solver': 'liblinear'}\n",
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 64.80%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "            0.0   1.0   2.0         3.0  accuracy   macro avg  weighted avg\n",
      "precision   0.0   0.0   0.0    0.647959  0.647959    0.161990      0.419851\n",
      "recall      0.0   0.0   0.0    1.000000  0.647959    0.250000      0.647959\n",
      "f1-score    0.0   0.0   0.0    0.786378  0.647959    0.196594      0.509541\n",
      "support    43.0  71.0  24.0  254.000000  0.647959  392.000000    392.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[  0   0   0  43]\n",
      " [  0   0   0  71]\n",
      " [  0   0   0  24]\n",
      " [  0   0   0 254]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 70.71%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "           0.0   1.0  2.0        3.0  accuracy  macro avg  weighted avg\n",
      "precision  0.0   0.0  0.0   0.707071  0.707071   0.176768      0.499949\n",
      "recall     0.0   0.0  0.0   1.000000  0.707071   0.250000      0.707071\n",
      "f1-score   0.0   0.0  0.0   0.828402  0.707071   0.207101      0.585739\n",
      "support    6.0  16.0  7.0  70.000000  0.707071  99.000000     99.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[ 0  0  0  6]\n",
      " [ 0  0  0 16]\n",
      " [ 0  0  0  7]\n",
      " [ 0  0  0 70]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\"C\": np.logspace(-4, 4, 20),\n",
    "          \"solver\": [\"liblinear\"]}\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "lr_cv = GridSearchCV(lr_clf, params, scoring=\"accuracy\", n_jobs=-1, verbose=1, cv=5)\n",
    "lr_cv.fit(X_train, y_train)\n",
    "best_params = lr_cv.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "lr_clf = LogisticRegression(**best_params)\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(lr_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(lr_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "54b79c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Training Accuracy %",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Testing Accuracy %",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "ea75aceb-93c7-40a5-b492-ef8e7f0141d2",
       "rows": [
        [
         "0",
         "Tuned Logistic Regression",
         "64.1399416909621",
         "70.27027027027027"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy %</th>\n",
       "      <th>Testing Accuracy %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned Logistic Regression</td>\n",
       "      <td>64.139942</td>\n",
       "      <td>70.27027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Training Accuracy %  Testing Accuracy %\n",
       "0  Tuned Logistic Regression            64.139942            70.27027"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = accuracy_score(y_test, lr_clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, lr_clf.predict(X_train)) * 100\n",
    "\n",
    "tuning_results_df = pd.DataFrame(\n",
    "    data=[[\"Tuned Logistic Regression\", train_score, test_score]], \n",
    "    columns=['Model', 'Training Accuracy %', 'Testing Accuracy %']\n",
    ")\n",
    "tuning_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4500c18",
   "metadata": {},
   "source": [
    "# 2. K-nearest neighbors Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ac41bcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = []\n",
    "test_score = []\n",
    "neighbors = range(1, 30)\n",
    "\n",
    "for k in neighbors:\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(X_train, y_train)\n",
    "    train_score.append(accuracy_score(y_train, model.predict(X_train)))\n",
    "#     test_score.append(accuracy_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "14dbd622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum KNN score on the test data: 100.00%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "plt.plot(neighbors, train_score, label=\"Train score\")\n",
    "# plt.plot(neighbors, test_score, label=\"Test score\")\n",
    "plt.xticks(np.arange(1, 21, 1))\n",
    "plt.xlabel(\"Number of neighbors\")\n",
    "plt.ylabel(\"Model score\")\n",
    "plt.legend()\n",
    "\n",
    "print(f\"Maximum KNN score on the test data: {max(train_score)*100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "41ba7071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 64.14%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "            0.0   1.0   2.0         3.0  accuracy   macro avg  weighted avg\n",
      "precision   0.0   0.0   0.0    0.641399  0.641399    0.160350      0.411393\n",
      "recall      0.0   0.0   0.0    1.000000  0.641399    0.250000      0.641399\n",
      "f1-score    0.0   0.0   0.0    0.781528  0.641399    0.195382      0.501271\n",
      "support    38.0  64.0  21.0  220.000000  0.641399  343.000000    343.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[  0   0   0  38]\n",
      " [  0   0   0  64]\n",
      " [  0   0   0  21]\n",
      " [  0   0   0 220]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 70.27%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "            0.0   1.0   2.0         3.0  accuracy   macro avg  weighted avg\n",
      "precision   0.0   0.0   0.0    0.702703  0.702703    0.175676      0.493791\n",
      "recall      0.0   0.0   0.0    1.000000  0.702703    0.250000      0.702703\n",
      "f1-score    0.0   0.0   0.0    0.825397  0.702703    0.206349      0.580009\n",
      "support    11.0  23.0  10.0  104.000000  0.702703  148.000000    148.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[  0   0   0  11]\n",
      " [  0   0   0  23]\n",
      " [  0   0   0  10]\n",
      " [  0   0   0 104]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier(n_neighbors=27)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(knn_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(knn_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7b6042f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Training Accuracy %",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Testing Accuracy %",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "18205347-08c3-49d1-adb8-0e0a606cfbcc",
       "rows": [
        [
         "0",
         "Tuned Logistic Regression",
         "64.1399416909621",
         "70.27027027027027"
        ],
        [
         "1",
         "Tuned K-nearest neighbors",
         "64.1399416909621",
         "70.27027027027027"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy %</th>\n",
       "      <th>Testing Accuracy %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned Logistic Regression</td>\n",
       "      <td>64.139942</td>\n",
       "      <td>70.27027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuned K-nearest neighbors</td>\n",
       "      <td>64.139942</td>\n",
       "      <td>70.27027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Training Accuracy %  Testing Accuracy %\n",
       "0  Tuned Logistic Regression            64.139942            70.27027\n",
       "1  Tuned K-nearest neighbors            64.139942            70.27027"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = accuracy_score(y_test, knn_clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, knn_clf.predict(X_train)) * 100\n",
    "\n",
    "results_df_2 = pd.DataFrame(\n",
    "    data=[[\"Tuned K-nearest neighbors\", train_score, test_score]], \n",
    "    columns=['Model', 'Training Accuracy %', 'Testing Accuracy %']\n",
    ")\n",
    "\n",
    "tuning_results_df = pd.concat([tuning_results_df, results_df_2], ignore_index=True)\n",
    "tuning_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404d8798",
   "metadata": {},
   "source": [
    "# 3. Support Vector Machine Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6a9fe4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 147 candidates, totalling 735 fits\n",
      "Best params: {'C': 0.1, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 64.14%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "            0.0   1.0   2.0         3.0  accuracy   macro avg  weighted avg\n",
      "precision   0.0   0.0   0.0    0.641399  0.641399    0.160350      0.411393\n",
      "recall      0.0   0.0   0.0    1.000000  0.641399    0.250000      0.641399\n",
      "f1-score    0.0   0.0   0.0    0.781528  0.641399    0.195382      0.501271\n",
      "support    38.0  64.0  21.0  220.000000  0.641399  343.000000    343.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[  0   0   0  38]\n",
      " [  0   0   0  64]\n",
      " [  0   0   0  21]\n",
      " [  0   0   0 220]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 70.27%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "            0.0   1.0   2.0         3.0  accuracy   macro avg  weighted avg\n",
      "precision   0.0   0.0   0.0    0.702703  0.702703    0.175676      0.493791\n",
      "recall      0.0   0.0   0.0    1.000000  0.702703    0.250000      0.702703\n",
      "f1-score    0.0   0.0   0.0    0.825397  0.702703    0.206349      0.580009\n",
      "support    11.0  23.0  10.0  104.000000  0.702703  148.000000    148.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[  0   0   0  11]\n",
      " [  0   0   0  23]\n",
      " [  0   0   0  10]\n",
      " [  0   0   0 104]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "svm_clf = SVC(kernel='rbf', gamma=0.1, C=1.0)\n",
    "\n",
    "params = {\"C\":(0.1, 0.5, 1, 2, 5, 10, 20), \n",
    "          \"gamma\":(0.001, 0.01, 0.1, 0.25, 0.5, 0.75, 1), \n",
    "          \"kernel\":('linear', 'poly', 'rbf')}\n",
    "\n",
    "svm_cv = GridSearchCV(svm_clf, params, n_jobs=-1, cv=5, verbose=1, scoring=\"accuracy\")\n",
    "svm_cv.fit(X_train, y_train)\n",
    "best_params = svm_cv.best_params_\n",
    "print(f\"Best params: {best_params}\")\n",
    "\n",
    "svm_clf = SVC(**best_params)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(svm_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(svm_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1eebeb35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Training Accuracy %",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Testing Accuracy %",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "a87e9d5b-c61f-4005-b4f2-8f6277b74f2e",
       "rows": [
        [
         "0",
         "Tuned Logistic Regression",
         "64.1399416909621",
         "70.27027027027027"
        ],
        [
         "1",
         "Tuned K-nearest neighbors",
         "64.1399416909621",
         "70.27027027027027"
        ],
        [
         "2",
         "Tuned Support Vector Machine",
         "64.1399416909621",
         "70.27027027027027"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy %</th>\n",
       "      <th>Testing Accuracy %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned Logistic Regression</td>\n",
       "      <td>64.139942</td>\n",
       "      <td>70.27027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuned K-nearest neighbors</td>\n",
       "      <td>64.139942</td>\n",
       "      <td>70.27027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tuned Support Vector Machine</td>\n",
       "      <td>64.139942</td>\n",
       "      <td>70.27027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model  Training Accuracy %  Testing Accuracy %\n",
       "0     Tuned Logistic Regression            64.139942            70.27027\n",
       "1     Tuned K-nearest neighbors            64.139942            70.27027\n",
       "2  Tuned Support Vector Machine            64.139942            70.27027"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = accuracy_score(y_test, svm_clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, svm_clf.predict(X_train)) * 100\n",
    "\n",
    "results_df_2 = pd.DataFrame(\n",
    "    data=[[\"Tuned Support Vector Machine\", train_score, test_score]], \n",
    "    columns=['Model', 'Training Accuracy %', 'Testing Accuracy %']\n",
    ")\n",
    "tuning_results_df = pd.concat([tuning_results_df, results_df_2], ignore_index=True)\n",
    "tuning_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13f667b",
   "metadata": {},
   "source": [
    "# 4. Decision Tree Classifier Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "6bd95c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4332 candidates, totalling 21660 fits\n",
      "Best_params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 67.69%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "              0           1     2          3           4  accuracy  \\\n",
      "precision   0.0    0.818182   0.0   0.812500    0.663093   0.67688   \n",
      "recall      0.0    0.247706   0.0   0.320988    0.993119   0.67688   \n",
      "f1-score    0.0    0.380282   0.0   0.460177    0.795225   0.67688   \n",
      "support    45.0  109.000000  47.0  81.000000  436.000000   0.67688   \n",
      "\n",
      "            macro avg  weighted avg  \n",
      "precision    0.458755      0.618528  \n",
      "recall       0.312363      0.676880  \n",
      "f1-score     0.327137      0.592539  \n",
      "support    718.000000    718.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[  0   1   0   2  42]\n",
      " [  0  27   0   1  81]\n",
      " [  0   0   0   0  47]\n",
      " [  0   5   0  26  50]\n",
      " [  0   0   0   3 433]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 69.81%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "              0          1     2          3           4  accuracy   macro avg  \\\n",
      "precision   0.0   0.714286   0.0   0.687500    0.698246  0.698052    0.420006   \n",
      "recall      0.0   0.121951   0.0   0.333333    0.990050  0.698052    0.289067   \n",
      "f1-score    0.0   0.208333   0.0   0.448980    0.818930  0.698052    0.295249   \n",
      "support    19.0  41.000000  14.0  33.000000  201.000000  0.698052  308.000000   \n",
      "\n",
      "           weighted avg  \n",
      "precision      0.624417  \n",
      "recall         0.698052  \n",
      "f1-score       0.610269  \n",
      "support      308.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[  0   0   0   2  17]\n",
      " [  0   5   0   1  35]\n",
      " [  0   0   0   0  14]\n",
      " [  0   2   0  11  20]\n",
      " [  0   0   0   2 199]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "params = {\"criterion\":(\"gini\", \"entropy\"), \n",
    "          \"splitter\":(\"best\", \"random\"), \n",
    "          \"max_depth\":(list(range(1, 20))), \n",
    "          \"min_samples_split\":[2, 3, 4], \n",
    "          \"min_samples_leaf\":list(range(1, 20))\n",
    "          }\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_cv = GridSearchCV(tree_clf, params, scoring=\"accuracy\", n_jobs=-1, verbose=1, cv=5)\n",
    "tree_cv.fit(X_train, y_train)\n",
    "best_params = tree_cv.best_params_\n",
    "print(f'Best_params: {best_params}')\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(**best_params)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(tree_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(tree_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e1733840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Training Accuracy %",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Testing Accuracy %",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "659a7c3b-2440-4002-8a4b-00b38888f66c",
       "rows": [
        [
         "0",
         "Tuned Logistic Regression",
         "100.0",
         "67.20779220779221"
        ],
        [
         "1",
         "Tuned K-nearest neighbors",
         "62.53481894150418",
         "66.23376623376623"
        ],
        [
         "2",
         "Tuned Support Vector Machine",
         "100.0",
         "67.20779220779221"
        ],
        [
         "3",
         "Tuned Decision Tree Classifier",
         "67.68802228412257",
         "69.8051948051948"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy %</th>\n",
       "      <th>Testing Accuracy %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned Logistic Regression</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>67.207792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuned K-nearest neighbors</td>\n",
       "      <td>62.534819</td>\n",
       "      <td>66.233766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tuned Support Vector Machine</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>67.207792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuned Decision Tree Classifier</td>\n",
       "      <td>67.688022</td>\n",
       "      <td>69.805195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model  Training Accuracy %  Testing Accuracy %\n",
       "0       Tuned Logistic Regression           100.000000           67.207792\n",
       "1       Tuned K-nearest neighbors            62.534819           66.233766\n",
       "2    Tuned Support Vector Machine           100.000000           67.207792\n",
       "3  Tuned Decision Tree Classifier            67.688022           69.805195"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = accuracy_score(y_test, tree_clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, tree_clf.predict(X_train)) * 100\n",
    "\n",
    "results_df_2 = pd.DataFrame(\n",
    "    data=[[\"Tuned Decision Tree Classifier\", train_score, test_score]], \n",
    "    columns=['Model', 'Training Accuracy %', 'Testing Accuracy %']\n",
    ")\n",
    "tuning_results_df = pd.concat([tuning_results_df, results_df_2], ignore_index=True)\n",
    "tuning_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c85c615",
   "metadata": {},
   "source": [
    "# 5. Random Forest Classifier Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc48b850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1080 candidates, totalling 5400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "1800 fits failed out of a total of 5400.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1279 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "521 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.64797144 0.64797144 0.64797144]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'bootstrap': False, 'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 100.00%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "            0.0   1.0   2.0    3.0  accuracy  macro avg  weighted avg\n",
      "precision   1.0   1.0   1.0    1.0       1.0        1.0           1.0\n",
      "recall      1.0   1.0   1.0    1.0       1.0        1.0           1.0\n",
      "f1-score    1.0   1.0   1.0    1.0       1.0        1.0           1.0\n",
      "support    43.0  71.0  24.0  254.0       1.0      392.0         392.0\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[ 43   0   0   0]\n",
      " [  0  71   0   0]\n",
      " [  0   0  24   0]\n",
      " [  0   0   0 254]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 74.75%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "           0.0        1.0       2.0        3.0  accuracy  macro avg  \\\n",
      "precision  0.0   1.000000  1.000000   0.736842  0.747475   0.684211   \n",
      "recall     0.0   0.187500  0.142857   1.000000  0.747475   0.332589   \n",
      "f1-score   0.0   0.315789  0.250000   0.848485  0.747475   0.353569   \n",
      "support    6.0  16.000000  7.000000  70.000000  0.747475  99.000000   \n",
      "\n",
      "           weighted avg  \n",
      "precision      0.753323  \n",
      "recall         0.747475  \n",
      "f1-score       0.668652  \n",
      "support       99.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[ 0  0  0  6]\n",
      " [ 0  3  0 13]\n",
      " [ 0  0  1  6]\n",
      " [ 0  0  0 70]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [500, 900, 1100, 1500]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [2, 3, 5, 10, 15, None]\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "params_grid = {\n",
    "    'n_estimators': [100, 200, 300, 500, 1000],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "              }\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "rf_cv = GridSearchCV(rf_clf, params_grid, scoring=\"accuracy\", cv=5, verbose=1, n_jobs=-1)\n",
    "rf_cv.fit(X_train, y_train)\n",
    "best_params = rf_cv.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "rf_clf = RandomForestClassifier(**best_params)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "f1bf82f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Training Accuracy %",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Testing Accuracy %",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "67e7eee8-8e5b-4000-807f-dc03d042ea57",
       "rows": [
        [
         "0",
         "Tuned Logistic Regression",
         "100.0",
         "67.20779220779221"
        ],
        [
         "1",
         "Tuned K-nearest neighbors",
         "62.53481894150418",
         "66.23376623376623"
        ],
        [
         "2",
         "Tuned Support Vector Machine",
         "100.0",
         "67.20779220779221"
        ],
        [
         "3",
         "Tuned Decision Tree Classifier",
         "67.68802228412257",
         "69.8051948051948"
        ],
        [
         "4",
         "Tuned Random Forest Classifier",
         "99.86072423398329",
         "69.48051948051948"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy %</th>\n",
       "      <th>Testing Accuracy %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned Logistic Regression</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>67.207792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuned K-nearest neighbors</td>\n",
       "      <td>62.534819</td>\n",
       "      <td>66.233766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tuned Support Vector Machine</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>67.207792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuned Decision Tree Classifier</td>\n",
       "      <td>67.688022</td>\n",
       "      <td>69.805195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned Random Forest Classifier</td>\n",
       "      <td>99.860724</td>\n",
       "      <td>69.480519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model  Training Accuracy %  Testing Accuracy %\n",
       "0       Tuned Logistic Regression           100.000000           67.207792\n",
       "1       Tuned K-nearest neighbors            62.534819           66.233766\n",
       "2    Tuned Support Vector Machine           100.000000           67.207792\n",
       "3  Tuned Decision Tree Classifier            67.688022           69.805195\n",
       "4  Tuned Random Forest Classifier            99.860724           69.480519"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = accuracy_score(y_test, rf_clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, rf_clf.predict(X_train)) * 100\n",
    "\n",
    "results_df_2 = pd.DataFrame(\n",
    "    data=[[\"Tuned Random Forest Classifier\", train_score, test_score]], \n",
    "    columns=['Model', 'Training Accuracy %', 'Testing Accuracy %']\n",
    ")\n",
    "tuning_results_df = pd.concat([tuning_results_df, results_df_2], ignore_index=True)\n",
    "tuning_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab111821",
   "metadata": {},
   "source": [
    "# 6. XGBoost Classifier Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "13f90089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 150 candidates, totalling 750 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[200]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      9\u001b[39m xgb_clf = XGBClassifier(use_label_encoder=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     10\u001b[39m xgb_cv = RandomizedSearchCV(\n\u001b[32m     11\u001b[39m     xgb_clf, param_grid, cv=\u001b[32m5\u001b[39m, n_iter=\u001b[32m150\u001b[39m, \n\u001b[32m     12\u001b[39m     scoring=\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m, verbose=\u001b[32m1\u001b[39m\n\u001b[32m     13\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mxgb_cv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m best_params = xgb_cv.best_params_\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest paramters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1951\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1950\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1951\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1952\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1953\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1954\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1955\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    966\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    967\u001b[39m         )\n\u001b[32m    968\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1760\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1763\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1765\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1767\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "param_grid = dict(\n",
    "    n_estimators=stats.randint(10, 1000),\n",
    "    max_depth=stats.randint(1, 10),\n",
    "    learning_rate=stats.uniform(0, 1)\n",
    ")\n",
    "\n",
    "xgb_clf = XGBClassifier(use_label_encoder=False)\n",
    "xgb_cv = RandomizedSearchCV(\n",
    "    xgb_clf, param_grid, cv=5, n_iter=150, \n",
    "    scoring='accuracy', n_jobs=-1, verbose=1\n",
    ")\n",
    "xgb_cv.fit(X_train, y_train)\n",
    "best_params = xgb_cv.best_params_\n",
    "print(f\"Best paramters: {best_params}\")\n",
    "\n",
    "xgb_clf = XGBClassifier(**best_params)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(xgb_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(xgb_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38f2d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = accuracy_score(y_test, xgb_clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, xgb_clf.predict(X_train)) * 100\n",
    "\n",
    "results_df_2 = pd.DataFrame(\n",
    "    data=[[\"Tuned XGBoost Classifier\", train_score, test_score]], \n",
    "    columns=['Model', 'Training Accuracy %', 'Testing Accuracy %']\n",
    ")\n",
    "tuning_results_df = pd.concat([tuning_results_df, results_df_2], ignore_index=True)\n",
    "tuning_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9045dcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef0d5cd",
   "metadata": {},
   "source": [
    "# 6. Features Importance According to Random Forest and XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "383629fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_imp(df, model):\n",
    "    fi = pd.DataFrame()\n",
    "    fi[\"feature\"] = df.Text\n",
    "    fi[\"importance\"] = model.feature_importances_\n",
    "    return fi.sort_values(by=\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "0ba98b3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'csr_matrix' object has no attribute 'Text'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[204]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mfeature_imp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrf_clf\u001b[49m\u001b[43m)\u001b[49m.plot(kind=\u001b[33m'\u001b[39m\u001b[33mbarh\u001b[39m\u001b[33m'\u001b[39m, figsize=(\u001b[32m12\u001b[39m,\u001b[32m7\u001b[39m), legend=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[203]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mfeature_imp\u001b[39m\u001b[34m(df, model)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfeature_imp\u001b[39m(df, model):\n\u001b[32m      2\u001b[39m     fi = pd.DataFrame()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     fi[\u001b[33m\"\u001b[39m\u001b[33mfeature\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mText\u001b[49m\n\u001b[32m      4\u001b[39m     fi[\u001b[33m\"\u001b[39m\u001b[33mimportance\u001b[39m\u001b[33m\"\u001b[39m] = model.feature_importances_\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fi.sort_values(by=\u001b[33m\"\u001b[39m\u001b[33mimportance\u001b[39m\u001b[33m\"\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'csr_matrix' object has no attribute 'Text'"
     ]
    }
   ],
   "source": [
    "feature_imp(X, rf_clf).plot(kind='barh', figsize=(12,7), legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b11a6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp(X, xgb_clf).plot(kind='barh', figsize=(12,7), legend=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
