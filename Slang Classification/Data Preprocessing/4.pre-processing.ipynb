{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce365b45",
   "metadata": {},
   "source": [
    "## Data Integration merge all text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34dfbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "df = pd.read_csv('Original Data.csv')  # Replace 'your_file.csv' with your actual file path\n",
    "\n",
    "# Create DataFrame\n",
    "post_data = pd.DataFrame(df)\n",
    "\n",
    "# Step 1: Combine Title, Text, and Comments Data into separate rows\n",
    "\n",
    "# Convert Comments Data from string format to list\n",
    "post_data['Comments Data'] = post_data['Comments Data'].apply(ast.literal_eval)\n",
    "\n",
    "# Prepare the DataFrame for expanding to multiple rows\n",
    "expanded_data = []\n",
    "\n",
    "# Add the Title and Text as separate rows\n",
    "for _, row in post_data.iterrows():\n",
    "    # Add the title as a row\n",
    "    expanded_data.append({'Text': row['Title'], 'Category': 'No Slang', 'Date': datetime.fromtimestamp(row['Timestamp'], tz=timezone.utc).strftime('%Y-%m-%d %H:%M:%S'), 'Upvotes': row['Upvotes'], 'Subreddit': row['Subreddit']})\n",
    "    \n",
    "    # Add the text (if available)\n",
    "    if row['Text']:\n",
    "        expanded_data.append({'Text': row['Text'], 'Category': 'No Slang', 'Date': datetime.fromtimestamp(row['Timestamp'], tz=timezone.utc).strftime('%Y-%m-%d %H:%M:%S'), 'Upvotes': row['Upvotes'], 'Subreddit': row['Subreddit']})\n",
    "    \n",
    "    # Add each comment as a separate row\n",
    "    for comment in row['Comments Data']:\n",
    "        expanded_data.append({'Text': comment[0], 'Category': 'No Slang', 'Date': datetime.fromtimestamp(comment[2], tz=timezone.utc).strftime('%Y-%m-%d %H:%M:%S'), 'Upvotes': comment[1], 'Subreddit': row['Subreddit']})\n",
    "\n",
    "# Create the expanded DataFrame\n",
    "expanded_df = pd.DataFrame(expanded_data)\n",
    "\n",
    "expanded_df.to_csv('merge_all_text.csv', index=False)  # Saves the cleaned data to a new file\n",
    "\n",
    "print(expanded_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096145ca",
   "metadata": {},
   "source": [
    "## Reduce rows from 100000 to 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bb663f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data reduced and saved to reduced_output.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def reduce_csv_to_1000_rows(input_csv, output_csv):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    # If the dataset has more than 1000 rows, randomly sample 1000 rows\n",
    "    if len(df) > 1000:\n",
    "        df_reduced = df.sample(n=7100, random_state=42)  # random_state for reproducibility\n",
    "    else:\n",
    "        df_reduced = df  # if there are fewer than 1000 rows, keep all rows\n",
    "\n",
    "    # Save the reduced dataset to a new CSV file\n",
    "    df_reduced[[\"Text\", \"Subreddit\", \"Category\"]].to_csv(output_csv, index=False)\n",
    "\n",
    "    print(f\"Data reduced and saved to {output_csv}\")\n",
    "\n",
    "# Example usage\n",
    "input_csv = 'C:/personal/Code/S6/NLP/Slang Classification/Datas/merge_all_text.csv'  # Replace with your input CSV file path\n",
    "output_csv = 'reduced_output.csv'  # Replace with your desired output file path\n",
    "reduce_csv_to_1000_rows(input_csv, output_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b43d3a",
   "metadata": {},
   "source": [
    "# Reduce again for labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88449c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6092f420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Text       9939 non-null   object\n",
      " 1   Subreddit  10000 non-null  object\n",
      " 2   Category   10000 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 234.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = 'reduced_output_10000.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "text_column = 'Text'  # Replace with the actual column name containing text\n",
    "label_column = 'Category'  # Replace with the actual label column name\n",
    "\n",
    "# Show the first few rows of the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3386fec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Text'])\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b66fc6",
   "metadata": {},
   "source": [
    "## Cleaning data for labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec7fbea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Case Folding\n",
    "def case_folding(text):\n",
    "    if isinstance(text, str):  # Check if the value is a string\n",
    "        return text.lower()\n",
    "    else:\n",
    "        return \"\"  # Return an empty string for non-string values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29b6265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Cleaning (remove unwanted characters)\n",
    "def clean_text(text):\n",
    "    # Remove HTML tags, URLs, mentions (@user), hashtags (#), emojis, digits, and punctuation\n",
    "    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text)  # Remove mentions\n",
    "    text = re.sub(r'#\\w+', '', text)  # Remove hashtags\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove digits\n",
    "    text = re.sub(r'[\\U00010000-\\U0010ffff]', '', text)  # Remove emojis\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)  # hapus URL\n",
    "    # text = re.sub(r\"[^a-z\\s]\", \"\", text)  # hapus semua non-huruf\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # hapus spasi berlebih\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "084fc8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply all steps to the dataset\n",
    "def preprocess_text(text):\n",
    "    text = case_folding(text)  # Step 1: Case folding\n",
    "    text = clean_text(text)  # Step 2: Data cleaning\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce8334e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to each row in the dataset\n",
    "df['Text'] = df[text_column].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea720412",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(n=2000, random_state=42)  # random_state for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d55a5fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Text\", \"Subreddit\", \"Category\"]].to_csv('ready_for_labelling.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ad3aeb",
   "metadata": {},
   "source": [
    "# Dataset Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88e98820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb55805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = 'reduced_output_10000'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "text_column = 'Text'  # Replace with the actual column name containing text\n",
    "label_column = 'Category'  # Replace with the actual label column name\n",
    "\n",
    "# Show the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4690db6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the stemmer and lemmatizer\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f670275",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73f82f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Case Folding\n",
    "def case_folding(text):\n",
    "    if isinstance(text, str):  # Check if the value is a string\n",
    "        return text.lower()\n",
    "    else:\n",
    "        return \"\"  # Return an empty string for non-string values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8dfcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Cleaning (remove unwanted characters)\n",
    "def clean_text(text):\n",
    "    # Remove HTML tags, URLs, mentions (@user), hashtags (#), emojis, digits, and punctuation\n",
    "    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text)  # Remove mentions\n",
    "    text = re.sub(r'#\\w+', '', text)  # Remove hashtags\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove digits\n",
    "    text = re.sub(r'[\\U00010000-\\U0010ffff]', '', text)  # Remove emojis\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8c46ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Tokenization\n",
    "def tokenize(text):\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553f49bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Stopwords Removal\n",
    "def remove_stopwords(tokens):\n",
    "    stop_words = set(stopwords.words('indonesian'))  # Change to 'english' for English stopwords\n",
    "    return [word for word in tokens if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b033b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Stemming and Lemmatization\n",
    "def stem_and_lemmatize(tokens, use_stemming=True):\n",
    "    if use_stemming:\n",
    "        return [stemmer.stem(word) for word in tokens]\n",
    "    else:\n",
    "        return [lemmatizer.lemmatize(word) for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1c2e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Manual Padding/Truncating\n",
    "def padding_truncating(tokens, max_len=100):\n",
    "    # If the sequence is shorter than max_len, pad with 'PAD' tokens\n",
    "    if len(tokens) < max_len:\n",
    "        tokens += ['PAD'] * (max_len - len(tokens))\n",
    "    # If the sequence is longer than max_len, truncate it\n",
    "    elif len(tokens) > max_len:\n",
    "        tokens = tokens[:max_len]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb3b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply all steps to the dataset\n",
    "def preprocess_text(text, use_stemming=True):\n",
    "    text = case_folding(text)  # Step 1: Case folding\n",
    "    text = clean_text(text)  # Step 2: Data cleaning\n",
    "    tokens = tokenize(text)  # Step 3: Tokenization\n",
    "    tokens = remove_stopwords(tokens)  # Step 4: Stopwords removal\n",
    "    tokens = stem_and_lemmatize(tokens, use_stemming)  # Step 5: Stemming/Lemmatization\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98a519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to each row in the dataset\n",
    "df['processed_text'] = df[text_column].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaf16e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Padding/Truncating and Text-to-Numeric Transformation\n",
    "# Assuming 'processed_text' column contains tokenized text\n",
    "df['padded_text'] = df['processed_text'].apply(lambda x: padding_truncating(x, max_len=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b4839e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Category  Category_Label\n",
      "0          No Slang               4\n",
      "3          No Slang               4\n",
      "4          No Slang               4\n",
      "5    Internet Slang               1\n",
      "6          No Slang               4\n",
      "7          No Slang               4\n",
      "8   Offensive Slang               3\n",
      "10   Internet Slang               1\n",
      "11         No Slang               4\n",
      "12         No Slang               4\n"
     ]
    }
   ],
   "source": [
    "# 8. Label Encoding\n",
    "def encode_labels(df, label_column):\n",
    "    encoder = LabelEncoder()\n",
    "    df[label_column] = encoder.fit_transform(df[label_column])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb572a7",
   "metadata": {},
   "source": [
    "# Vectorize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd96750a",
   "metadata": {},
   "source": [
    "# Models Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f606218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n",
    "    if train:\n",
    "        pred = clf.predict(X_train)\n",
    "        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        pred = clf.predict(X_test)\n",
    "        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c270fc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = tfidf_matrix\n",
    "y = df_cleaned[\"Category_Label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b66c50",
   "metadata": {},
   "source": [
    "# 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34ec3236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 67.31%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                    0           1           2           3            4  \\\n",
      "precision    0.666667    0.885714    1.000000    0.958333     0.659061   \n",
      "recall       0.008811    0.190965    0.005181    0.216301     0.999506   \n",
      "f1-score     0.017391    0.314189    0.010309    0.352941     0.794343   \n",
      "support    227.000000  487.000000  193.000000  319.000000  2023.000000   \n",
      "\n",
      "           accuracy    macro avg  weighted avg  \n",
      "precision   0.67313     0.833955      0.743203  \n",
      "recall      0.67313     0.284153      0.673130  \n",
      "f1-score    0.67313     0.297835      0.578175  \n",
      "support     0.67313  3249.000000   3249.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[   2    4    0    1  220]\n",
      " [   0   93    0    1  393]\n",
      " [   0    1    1    1  190]\n",
      " [   1    6    0   69  243]\n",
      " [   0    1    0    0 2022]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 65.40%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "              0           1     2           3           4  accuracy  \\\n",
      "precision   0.0    0.878788   0.0    0.909091    0.646405  0.653984   \n",
      "recall      0.0    0.132420   0.0    0.073529    0.998855  0.653984   \n",
      "f1-score    0.0    0.230159   0.0    0.136054    0.784878  0.653984   \n",
      "support    92.0  219.000000  73.0  136.000000  873.000000  0.653984   \n",
      "\n",
      "             macro avg  weighted avg  \n",
      "precision     0.486857      0.632019  \n",
      "recall        0.240961      0.653984  \n",
      "f1-score      0.230218      0.541355  \n",
      "support    1393.000000   1393.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[  0   1   0   1  90]\n",
      " [  0  29   0   0 190]\n",
      " [  0   0   0   0  73]\n",
      " [  0   2   0  10 124]\n",
      " [  0   1   0   0 872]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(lr_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(lr_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ca4310d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Training Accuracy %",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Testing Accuracy %",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "0d346b6c-f188-4b15-9e4d-4d62da506e2f",
       "rows": [
        [
         "0",
         "Logistic Regression",
         "67.31301939058172",
         "65.39842067480258"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy %</th>\n",
       "      <th>Testing Accuracy %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>67.313019</td>\n",
       "      <td>65.398421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Training Accuracy %  Testing Accuracy %\n",
       "0  Logistic Regression            67.313019           65.398421"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = accuracy_score(y_test, lr_clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, lr_clf.predict(X_train)) * 100\n",
    "\n",
    "results_df = pd.DataFrame(data=[[\"Logistic Regression\", train_score, test_score]], columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a018a7b",
   "metadata": {},
   "source": [
    "# 2. K-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65fc3dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 69.96%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                    0           1           2           3            4  \\\n",
      "precision    0.585106    0.676329    0.586957    0.636986     0.710450   \n",
      "recall       0.242291    0.287474    0.139896    0.291536     0.967870   \n",
      "f1-score     0.342679    0.403458    0.225941    0.400000     0.819418   \n",
      "support    227.000000  487.000000  193.000000  319.000000  2023.000000   \n",
      "\n",
      "           accuracy    macro avg  weighted avg  \n",
      "precision    0.6996     0.639166      0.682029  \n",
      "recall       0.6996     0.385813      0.699600  \n",
      "f1-score     0.6996     0.438299      0.647326  \n",
      "support      0.6996  3249.000000   3249.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[  55   11    3   15  143]\n",
      " [  13  140    6   16  312]\n",
      " [   5   12   27    3  146]\n",
      " [  10   16    3   93  197]\n",
      " [  11   28    7   19 1958]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 60.30%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   0           1          2           3           4  accuracy  \\\n",
      "precision   0.071429    0.416667   0.130435    0.160000    0.655629  0.603015   \n",
      "recall      0.021739    0.159817   0.041096    0.058824    0.907216  0.603015   \n",
      "f1-score    0.033333    0.231023   0.062500    0.086022    0.761173  0.603015   \n",
      "support    92.000000  219.000000  73.000000  136.000000  873.000000  0.603015   \n",
      "\n",
      "             macro avg  weighted avg  \n",
      "precision     0.286832      0.503566  \n",
      "recall        0.237738      0.603015  \n",
      "f1-score      0.234810      0.527226  \n",
      "support    1393.000000   1393.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[  2  11   2   5  72]\n",
      " [  3  35   6  11 164]\n",
      " [  3   4   3   1  62]\n",
      " [  5   3   2   8 118]\n",
      " [ 15  31  10  25 792]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(knn_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(knn_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14b1d93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Training Accuracy %",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Testing Accuracy %",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "cb6becff-c3a7-44c3-b1df-7e12cb16eaec",
       "rows": [
        [
         "0",
         "Logistic Regression",
         "67.31301939058172",
         "65.39842067480258"
        ],
        [
         "1",
         "K-nearest neighbors",
         "69.95998768851955",
         "60.30150753768844"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy %</th>\n",
       "      <th>Testing Accuracy %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>67.313019</td>\n",
       "      <td>65.398421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-nearest neighbors</td>\n",
       "      <td>69.959988</td>\n",
       "      <td>60.301508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Training Accuracy %  Testing Accuracy %\n",
       "0  Logistic Regression            67.313019           65.398421\n",
       "1  K-nearest neighbors            69.959988           60.301508"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = accuracy_score(y_test, knn_clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, knn_clf.predict(X_train)) * 100\n",
    "\n",
    "results_df_2 = pd.DataFrame(data=[[\"K-nearest neighbors\", train_score, test_score]], \n",
    "                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\n",
    "results_df = pd.concat([results_df, results_df_2], ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f897a97c",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "026a241a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 63.71%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "               0           1      2           3            4  accuracy  \\\n",
      "precision    0.0    0.913043    0.0    1.000000     0.632583  0.637119   \n",
      "recall       0.0    0.086242    0.0    0.015674     1.000000  0.637119   \n",
      "f1-score     0.0    0.157598    0.0    0.030864     0.774947  0.637119   \n",
      "support    227.0  487.000000  193.0  319.000000  2023.000000  0.637119   \n",
      "\n",
      "             macro avg  weighted avg  \n",
      "precision     0.509125      0.628922  \n",
      "recall        0.220383      0.637119  \n",
      "f1-score      0.192682      0.509177  \n",
      "support    3249.000000   3249.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[   0    1    0    0  226]\n",
      " [   0   42    0    0  445]\n",
      " [   0    0    0    0  193]\n",
      " [   0    3    0    5  311]\n",
      " [   0    0    0    0 2023]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 63.53%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "              0           1     2      3           4  accuracy    macro avg  \\\n",
      "precision   0.0    0.923077   0.0    0.0    0.632609  0.635319     0.311137   \n",
      "recall      0.0    0.054795   0.0    0.0    1.000000  0.635319     0.210959   \n",
      "f1-score    0.0    0.103448   0.0    0.0    0.774967  0.635319     0.175683   \n",
      "support    92.0  219.000000  73.0  136.0  873.000000  0.635319  1393.000000   \n",
      "\n",
      "           weighted avg  \n",
      "precision      0.541580  \n",
      "recall         0.635319  \n",
      "f1-score       0.501939  \n",
      "support     1393.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[  0   0   0   0  92]\n",
      " [  0  12   0   0 207]\n",
      " [  0   0   0   0  73]\n",
      " [  0   1   0   0 135]\n",
      " [  0   0   0   0 873]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "svm_clf = SVC(kernel='rbf', gamma=0.1, C=1.0)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(svm_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(svm_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4611f20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Training Accuracy %",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Testing Accuracy %",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "22882ce4-4d14-424d-a8ce-514b2e62e778",
       "rows": [
        [
         "0",
         "Logistic Regression",
         "67.31301939058172",
         "65.39842067480258"
        ],
        [
         "1",
         "K-nearest neighbors",
         "69.95998768851955",
         "60.30150753768844"
        ],
        [
         "2",
         "Support Vector Machine",
         "63.711911357340725",
         "63.53194544149318"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy %</th>\n",
       "      <th>Testing Accuracy %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>67.313019</td>\n",
       "      <td>65.398421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-nearest neighbors</td>\n",
       "      <td>69.959988</td>\n",
       "      <td>60.301508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>63.711911</td>\n",
       "      <td>63.531945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Training Accuracy %  Testing Accuracy %\n",
       "0     Logistic Regression            67.313019           65.398421\n",
       "1     K-nearest neighbors            69.959988           60.301508\n",
       "2  Support Vector Machine            63.711911           63.531945"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = accuracy_score(y_test, svm_clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, svm_clf.predict(X_train)) * 100\n",
    "\n",
    "results_df_2 = pd.DataFrame(data=[[\"Support Vector Machine\", train_score, test_score]], \n",
    "                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\n",
    "results_df = pd.concat([results_df, results_df_2], ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1163fa03",
   "metadata": {},
   "source": [
    "# 4. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c54c0fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 99.91%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                    0           1           2      3            4  accuracy  \\\n",
      "precision    0.995614    0.995910    1.000000    1.0     1.000000  0.999077   \n",
      "recall       1.000000    1.000000    0.989637    1.0     0.999506  0.999077   \n",
      "f1-score     0.997802    0.997951    0.994792    1.0     0.999753  0.999077   \n",
      "support    227.000000  487.000000  193.000000  319.0  2023.000000  0.999077   \n",
      "\n",
      "             macro avg  weighted avg  \n",
      "precision     0.998305      0.999081  \n",
      "recall        0.997829      0.999077  \n",
      "f1-score      0.998059      0.999076  \n",
      "support    3249.000000   3249.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[ 227    0    0    0    0]\n",
      " [   0  487    0    0    0]\n",
      " [   0    2  191    0    0]\n",
      " [   0    0    0  319    0]\n",
      " [   1    0    0    0 2022]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 58.79%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   0           1          2           3           4  accuracy  \\\n",
      "precision   0.094118    0.459596   0.109375    0.406780    0.716595   0.58794   \n",
      "recall      0.086957    0.415525   0.095890    0.352941    0.761741   0.58794   \n",
      "f1-score    0.090395    0.436451   0.102190    0.377953    0.738479   0.58794   \n",
      "support    92.000000  219.000000  73.000000  136.000000  873.000000   0.58794   \n",
      "\n",
      "             macro avg  weighted avg  \n",
      "precision     0.357293      0.573011  \n",
      "recall        0.342611      0.587940  \n",
      "f1-score      0.349093      0.579650  \n",
      "support    1393.000000   1393.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[  8  11   4   8  61]\n",
      " [ 19  91   9  15  85]\n",
      " [  3  12   7   2  49]\n",
      " [ 10   6   4  48  68]\n",
      " [ 45  78  40  45 665]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(tree_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(tree_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed1d7218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Training Accuracy %",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Testing Accuracy %",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "54580755-b166-4ded-b703-436e9dc3404a",
       "rows": [
        [
         "0",
         "Logistic Regression",
         "67.31301939058172",
         "65.39842067480258"
        ],
        [
         "1",
         "K-nearest neighbors",
         "69.95998768851955",
         "60.30150753768844"
        ],
        [
         "2",
         "Support Vector Machine",
         "63.711911357340725",
         "63.53194544149318"
        ],
        [
         "3",
         "Decision Tree Classifier",
         "99.90766389658357",
         "58.79396984924623"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy %</th>\n",
       "      <th>Testing Accuracy %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>67.313019</td>\n",
       "      <td>65.398421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-nearest neighbors</td>\n",
       "      <td>69.959988</td>\n",
       "      <td>60.301508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>63.711911</td>\n",
       "      <td>63.531945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>99.907664</td>\n",
       "      <td>58.793970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  Training Accuracy %  Testing Accuracy %\n",
       "0       Logistic Regression            67.313019           65.398421\n",
       "1       K-nearest neighbors            69.959988           60.301508\n",
       "2    Support Vector Machine            63.711911           63.531945\n",
       "3  Decision Tree Classifier            99.907664           58.793970"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = accuracy_score(y_test, tree_clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, tree_clf.predict(X_train)) * 100\n",
    "\n",
    "results_df_2 = pd.DataFrame(data=[[\"Decision Tree Classifier\", train_score, test_score]], \n",
    "                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\n",
    "results_df = pd.concat([results_df, results_df_2], ignore_index=True)\n",
    "results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7964396f",
   "metadata": {},
   "source": [
    "#  5. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3b548bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 99.91%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                    0           1           2      3            4  accuracy  \\\n",
      "precision    1.000000    0.995910    1.000000    1.0     0.999506  0.999077   \n",
      "recall       0.995595    1.000000    0.989637    1.0     1.000000  0.999077   \n",
      "f1-score     0.997792    0.997951    0.994792    1.0     0.999753  0.999077   \n",
      "support    227.000000  487.000000  193.000000  319.0  2023.000000  0.999077   \n",
      "\n",
      "             macro avg  weighted avg  \n",
      "precision     0.999083      0.999079  \n",
      "recall        0.997046      0.999077  \n",
      "f1-score      0.998058      0.999075  \n",
      "support    3249.000000   3249.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[ 226    0    0    0    1]\n",
      " [   0  487    0    0    0]\n",
      " [   0    2  191    0    0]\n",
      " [   0    0    0  319    0]\n",
      " [   0    0    0    0 2023]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 68.41%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   0           1          2           3           4  accuracy  \\\n",
      "precision   0.222222    0.755814   0.166667    0.711538    0.687246  0.684135   \n",
      "recall      0.043478    0.296804   0.013699    0.272059    0.969072  0.684135   \n",
      "f1-score    0.072727    0.426230   0.025316    0.393617    0.804183  0.684135   \n",
      "support    92.000000  219.000000  73.000000  136.000000  873.000000  0.684135   \n",
      "\n",
      "             macro avg  weighted avg  \n",
      "precision     0.508697      0.642405  \n",
      "recall        0.319022      0.684135  \n",
      "f1-score      0.344415      0.615554  \n",
      "support    1393.000000   1393.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[  4   2   0   2  84]\n",
      " [  8  65   2   5 139]\n",
      " [  0   5   1   0  67]\n",
      " [  2   2   0  37  95]\n",
      " [  4  12   3   8 846]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e27369a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Training Accuracy %",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Testing Accuracy %",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "f6221b19-f5af-4b32-8f4b-60ee6dafeccd",
       "rows": [
        [
         "0",
         "Logistic Regression",
         "67.31301939058172",
         "65.39842067480258"
        ],
        [
         "1",
         "K-nearest neighbors",
         "69.95998768851955",
         "60.30150753768844"
        ],
        [
         "2",
         "Support Vector Machine",
         "63.711911357340725",
         "63.53194544149318"
        ],
        [
         "3",
         "Decision Tree Classifier",
         "99.90766389658357",
         "58.79396984924623"
        ],
        [
         "4",
         "Random Forest Classifier",
         "99.90766389658357",
         "68.413496051687"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy %</th>\n",
       "      <th>Testing Accuracy %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>67.313019</td>\n",
       "      <td>65.398421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-nearest neighbors</td>\n",
       "      <td>69.959988</td>\n",
       "      <td>60.301508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>63.711911</td>\n",
       "      <td>63.531945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>99.907664</td>\n",
       "      <td>58.793970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>99.907664</td>\n",
       "      <td>68.413496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  Training Accuracy %  Testing Accuracy %\n",
       "0       Logistic Regression            67.313019           65.398421\n",
       "1       K-nearest neighbors            69.959988           60.301508\n",
       "2    Support Vector Machine            63.711911           63.531945\n",
       "3  Decision Tree Classifier            99.907664           58.793970\n",
       "4  Random Forest Classifier            99.907664           68.413496"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = accuracy_score(y_test, rf_clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, rf_clf.predict(X_train)) * 100\n",
    "\n",
    "results_df_2 = pd.DataFrame(data=[[\"Random Forest Classifier\", train_score, test_score]], \n",
    "                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\n",
    "results_df = pd.concat([results_df, results_df_2], ignore_index=True)\n",
    "results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c953791",
   "metadata": {},
   "source": [
    "# 6. XGBoost Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "810db141",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:19:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 95.26%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   0           1          2          3           4  accuracy  \\\n",
      "precision   1.000000    0.989583   1.000000   1.000000    0.929638  0.952646   \n",
      "recall      0.822222    0.871560   0.893617   0.913580    1.000000  0.952646   \n",
      "f1-score    0.902439    0.926829   0.943820   0.954839    0.963536  0.952646   \n",
      "support    45.000000  109.000000  47.000000  81.000000  436.000000  0.952646   \n",
      "\n",
      "            macro avg  weighted avg  \n",
      "precision    0.983844      0.955692  \n",
      "recall       0.900196      0.952646  \n",
      "f1-score     0.938293      0.951863  \n",
      "support    718.000000    718.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[ 37   0   0   0   8]\n",
      " [  0  95   0   0  14]\n",
      " [  0   0  42   0   5]\n",
      " [  0   1   0  74   6]\n",
      " [  0   0   0   0 436]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 64.94%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   0          1          2          3           4  accuracy  \\\n",
      "precision   0.125000   0.466667   0.142857   0.523810    0.700389  0.649351   \n",
      "recall      0.052632   0.170732   0.071429   0.333333    0.895522  0.649351   \n",
      "f1-score    0.074074   0.250000   0.095238   0.407407    0.786026  0.649351   \n",
      "support    19.000000  41.000000  14.000000  33.000000  201.000000  0.649351   \n",
      "\n",
      "            macro avg  weighted avg  \n",
      "precision    0.391744      0.589520  \n",
      "recall       0.304730      0.649351  \n",
      "f1-score     0.322549      0.598787  \n",
      "support    308.000000    308.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[  1   2   0   1  15]\n",
      " [  0   7   0   3  31]\n",
      " [  0   1   1   1  11]\n",
      " [  0   1   1  11  20]\n",
      " [  7   4   5   5 180]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_clf = XGBClassifier(use_label_encoder=False)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(xgb_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(xgb_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "06a541c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Training Accuracy %",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Testing Accuracy %",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "fbd5b85c-0e5a-457f-820e-7ba34aa13390",
       "rows": [
        [
         "0",
         "Logistic Regression",
         "61.97771587743732",
         "65.25974025974025"
        ],
        [
         "1",
         "K-nearest neighbors",
         "66.57381615598887",
         "57.7922077922078"
        ],
        [
         "2",
         "Support Vector Machine",
         "60.724233983286915",
         "65.25974025974025"
        ],
        [
         "3",
         "Decision Tree Classifier",
         "100.0",
         "60.064935064935064"
        ],
        [
         "4",
         "Random Forest Classifier",
         "100.0",
         "69.8051948051948"
        ],
        [
         "5",
         "XGBoost Classifier",
         "95.26462395543176",
         "64.93506493506493"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 6
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy %</th>\n",
       "      <th>Testing Accuracy %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>61.977716</td>\n",
       "      <td>65.259740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-nearest neighbors</td>\n",
       "      <td>66.573816</td>\n",
       "      <td>57.792208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>60.724234</td>\n",
       "      <td>65.259740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>60.064935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>69.805195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>95.264624</td>\n",
       "      <td>64.935065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  Training Accuracy %  Testing Accuracy %\n",
       "0       Logistic Regression            61.977716           65.259740\n",
       "1       K-nearest neighbors            66.573816           57.792208\n",
       "2    Support Vector Machine            60.724234           65.259740\n",
       "3  Decision Tree Classifier           100.000000           60.064935\n",
       "4  Random Forest Classifier           100.000000           69.805195\n",
       "5        XGBoost Classifier            95.264624           64.935065"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = accuracy_score(y_test, xgb_clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, xgb_clf.predict(X_train)) * 100\n",
    "\n",
    "results_df_2 = pd.DataFrame(data=[[\"XGBoost Classifier\", train_score, test_score]], \n",
    "                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\n",
    "results_df = pd.concat([results_df, results_df_2], ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca2209b",
   "metadata": {},
   "source": [
    "# 🤖 Models Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "673e6091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best parameters: {'C': 11.288378916846883, 'solver': 'liblinear'}\n",
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 100.00%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "              0      1     2     3      4  accuracy  macro avg  weighted avg\n",
      "precision   1.0    1.0   1.0   1.0    1.0       1.0        1.0           1.0\n",
      "recall      1.0    1.0   1.0   1.0    1.0       1.0        1.0           1.0\n",
      "f1-score    1.0    1.0   1.0   1.0    1.0       1.0        1.0           1.0\n",
      "support    45.0  109.0  47.0  81.0  436.0       1.0      718.0         718.0\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[ 45   0   0   0   0]\n",
      " [  0 109   0   0   0]\n",
      " [  0   0  47   0   0]\n",
      " [  0   0   0  81   0]\n",
      " [  0   0   0   0 436]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 67.21%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "              0          1     2          3           4  accuracy   macro avg  \\\n",
      "precision   0.0   0.500000   0.0   1.000000    0.675676  0.672078    0.435135   \n",
      "recall      0.0   0.121951   0.0   0.060606    0.995025  0.672078    0.235516   \n",
      "f1-score    0.0   0.196078   0.0   0.114286    0.804829  0.672078    0.223039   \n",
      "support    19.0  41.000000  14.0  33.000000  201.000000  0.672078  308.000000   \n",
      "\n",
      "           weighted avg  \n",
      "precision      0.614645  \n",
      "recall         0.672078  \n",
      "f1-score       0.563576  \n",
      "support      308.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[  0   1   0   0  18]\n",
      " [  0   5   0   0  36]\n",
      " [  0   1   0   0  13]\n",
      " [  0   2   0   2  29]\n",
      " [  0   1   0   0 200]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\"C\": np.logspace(-4, 4, 20),\n",
    "          \"solver\": [\"liblinear\"]}\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "lr_cv = GridSearchCV(lr_clf, params, scoring=\"accuracy\", n_jobs=-1, verbose=1, cv=5)\n",
    "lr_cv.fit(X_train, y_train)\n",
    "best_params = lr_cv.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "lr_clf = LogisticRegression(**best_params)\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(lr_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(lr_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "54b79c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Training Accuracy %",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Testing Accuracy %",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "57efa574-126d-41e9-9425-c6c0d7eb1e49",
       "rows": [
        [
         "0",
         "Tuned Logistic Regression",
         "100.0",
         "67.20779220779221"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy %</th>\n",
       "      <th>Testing Accuracy %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned Logistic Regression</td>\n",
       "      <td>100.0</td>\n",
       "      <td>67.207792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Training Accuracy %  Testing Accuracy %\n",
       "0  Tuned Logistic Regression                100.0           67.207792"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = accuracy_score(y_test, lr_clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, lr_clf.predict(X_train)) * 100\n",
    "\n",
    "tuning_results_df = pd.DataFrame(\n",
    "    data=[[\"Tuned Logistic Regression\", train_score, test_score]], \n",
    "    columns=['Model', 'Training Accuracy %', 'Testing Accuracy %']\n",
    ")\n",
    "tuning_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4500c18",
   "metadata": {},
   "source": [
    "# 2. K-nearest neighbors Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ac41bcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = []\n",
    "test_score = []\n",
    "neighbors = range(1, 30)\n",
    "\n",
    "for k in neighbors:\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(X_train, y_train)\n",
    "    train_score.append(accuracy_score(y_train, model.predict(X_train)))\n",
    "#     test_score.append(accuracy_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "14dbd622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum KNN score on the test data: 100.00%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "plt.plot(neighbors, train_score, label=\"Train score\")\n",
    "# plt.plot(neighbors, test_score, label=\"Test score\")\n",
    "plt.xticks(np.arange(1, 21, 1))\n",
    "plt.xlabel(\"Number of neighbors\")\n",
    "plt.ylabel(\"Model score\")\n",
    "plt.legend()\n",
    "\n",
    "print(f\"Maximum KNN score on the test data: {max(train_score)*100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "41ba7071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 62.53%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "              0           1     2          3           4  accuracy  \\\n",
      "precision   0.0    0.636364   0.0   1.000000    0.621969  0.625348   \n",
      "recall      0.0    0.064220   0.0   0.074074    1.000000  0.625348   \n",
      "f1-score    0.0    0.116667   0.0   0.137931    0.766931  0.625348   \n",
      "support    45.0  109.000000  47.0  81.000000  436.000000  0.625348   \n",
      "\n",
      "            macro avg  weighted avg  \n",
      "precision    0.451666      0.587106  \n",
      "recall       0.227659      0.625348  \n",
      "f1-score     0.204306      0.498984  \n",
      "support    718.000000    718.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[  0   0   0   0  45]\n",
      " [  0   7   0   0 102]\n",
      " [  0   0   0   0  47]\n",
      " [  0   4   0   6  71]\n",
      " [  0   0   0   0 436]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 66.23%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "              0          1     2     3           4  accuracy   macro avg  \\\n",
      "precision   0.0   0.625000   0.0   0.0    0.663333  0.662338    0.257667   \n",
      "recall      0.0   0.121951   0.0   0.0    0.990050  0.662338    0.222400   \n",
      "f1-score    0.0   0.204082   0.0   0.0    0.794411  0.662338    0.199699   \n",
      "support    19.0  41.000000  14.0  33.0  201.000000  0.662338  308.000000   \n",
      "\n",
      "           weighted avg  \n",
      "precision      0.516088  \n",
      "recall         0.662338  \n",
      "f1-score       0.545597  \n",
      "support      308.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[  0   0   0   0  19]\n",
      " [  0   5   0   0  36]\n",
      " [  0   0   0   0  14]\n",
      " [  0   1   0   0  32]\n",
      " [  0   2   0   0 199]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier(n_neighbors=27)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(knn_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(knn_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6042f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Training Accuracy %",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Testing Accuracy %",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "9310a917-2a9c-488b-a9c8-f155deba323e",
       "rows": [
        [
         "0",
         "Tuned Logistic Regression",
         "100.0",
         "67.20779220779221"
        ],
        [
         "1",
         "Tuned K-nearest neighbors",
         "62.53481894150418",
         "66.23376623376623"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy %</th>\n",
       "      <th>Testing Accuracy %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned Logistic Regression</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>67.207792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuned K-nearest neighbors</td>\n",
       "      <td>62.534819</td>\n",
       "      <td>66.233766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Training Accuracy %  Testing Accuracy %\n",
       "0  Tuned Logistic Regression           100.000000           67.207792\n",
       "1  Tuned K-nearest neighbors            62.534819           66.233766"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = accuracy_score(y_test, knn_clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, knn_clf.predict(X_train)) * 100\n",
    "\n",
    "results_df_2 = pd.DataFrame(\n",
    "    data=[[\"Tuned K-nearest neighbors\", train_score, test_score]], \n",
    "    columns=['Model', 'Training Accuracy %', 'Testing Accuracy %']\n",
    ")\n",
    "\n",
    "tuning_results_df = pd.concat([tuning_results_df, results_df_2], ignore_index=True)\n",
    "tuning_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404d8798",
   "metadata": {},
   "source": [
    "# 3. Support Vector Machine Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "6a9fe4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 147 candidates, totalling 735 fits\n",
      "Best params: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 100.00%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "              0      1     2     3      4  accuracy  macro avg  weighted avg\n",
      "precision   1.0    1.0   1.0   1.0    1.0       1.0        1.0           1.0\n",
      "recall      1.0    1.0   1.0   1.0    1.0       1.0        1.0           1.0\n",
      "f1-score    1.0    1.0   1.0   1.0    1.0       1.0        1.0           1.0\n",
      "support    45.0  109.0  47.0  81.0  436.0       1.0      718.0         718.0\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[ 45   0   0   0   0]\n",
      " [  0 109   0   0   0]\n",
      " [  0   0  47   0   0]\n",
      " [  0   0   0  81   0]\n",
      " [  0   0   0   0 436]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 67.21%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "              0          1     2          3           4  accuracy   macro avg  \\\n",
      "precision   0.0   0.461538   0.0   0.666667    0.681661  0.672078    0.361973   \n",
      "recall      0.0   0.146341   0.0   0.121212    0.980100  0.672078    0.249531   \n",
      "f1-score    0.0   0.222222   0.0   0.205128    0.804082  0.672078    0.246286   \n",
      "support    19.0  41.000000  14.0  33.000000  201.000000  0.672078  308.000000   \n",
      "\n",
      "           weighted avg  \n",
      "precision      0.577717  \n",
      "recall         0.672078  \n",
      "f1-score       0.576301  \n",
      "support      308.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[  0   1   0   0  18]\n",
      " [  0   6   0   1  34]\n",
      " [  0   1   0   0  13]\n",
      " [  0   2   0   4  27]\n",
      " [  0   3   0   1 197]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "svm_clf = SVC(kernel='rbf', gamma=0.1, C=1.0)\n",
    "\n",
    "params = {\"C\":(0.1, 0.5, 1, 2, 5, 10, 20), \n",
    "          \"gamma\":(0.001, 0.01, 0.1, 0.25, 0.5, 0.75, 1), \n",
    "          \"kernel\":('linear', 'poly', 'rbf')}\n",
    "\n",
    "svm_cv = GridSearchCV(svm_clf, params, n_jobs=-1, cv=5, verbose=1, scoring=\"accuracy\")\n",
    "svm_cv.fit(X_train, y_train)\n",
    "best_params = svm_cv.best_params_\n",
    "print(f\"Best params: {best_params}\")\n",
    "\n",
    "svm_clf = SVC(**best_params)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(svm_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(svm_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1eebeb35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Training Accuracy %",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Testing Accuracy %",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4ab32da3-e772-47bb-b13f-3f1d3064d0bc",
       "rows": [
        [
         "0",
         "Tuned Logistic Regression",
         "100.0",
         "67.20779220779221"
        ],
        [
         "1",
         "Tuned K-nearest neighbors",
         "62.53481894150418",
         "66.23376623376623"
        ],
        [
         "2",
         "Tuned Support Vector Machine",
         "100.0",
         "67.20779220779221"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy %</th>\n",
       "      <th>Testing Accuracy %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned Logistic Regression</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>67.207792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuned K-nearest neighbors</td>\n",
       "      <td>62.534819</td>\n",
       "      <td>66.233766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tuned Support Vector Machine</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>67.207792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model  Training Accuracy %  Testing Accuracy %\n",
       "0     Tuned Logistic Regression           100.000000           67.207792\n",
       "1     Tuned K-nearest neighbors            62.534819           66.233766\n",
       "2  Tuned Support Vector Machine           100.000000           67.207792"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = accuracy_score(y_test, svm_clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, svm_clf.predict(X_train)) * 100\n",
    "\n",
    "results_df_2 = pd.DataFrame(\n",
    "    data=[[\"Tuned Support Vector Machine\", train_score, test_score]], \n",
    "    columns=['Model', 'Training Accuracy %', 'Testing Accuracy %']\n",
    ")\n",
    "tuning_results_df = pd.concat([tuning_results_df, results_df_2], ignore_index=True)\n",
    "tuning_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13f667b",
   "metadata": {},
   "source": [
    "# 4. Decision Tree Classifier Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "6bd95c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4332 candidates, totalling 21660 fits\n",
      "Best_params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 5, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 67.69%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "              0           1     2          3           4  accuracy  \\\n",
      "precision   0.0    0.818182   0.0   0.812500    0.663093   0.67688   \n",
      "recall      0.0    0.247706   0.0   0.320988    0.993119   0.67688   \n",
      "f1-score    0.0    0.380282   0.0   0.460177    0.795225   0.67688   \n",
      "support    45.0  109.000000  47.0  81.000000  436.000000   0.67688   \n",
      "\n",
      "            macro avg  weighted avg  \n",
      "precision    0.458755      0.618528  \n",
      "recall       0.312363      0.676880  \n",
      "f1-score     0.327137      0.592539  \n",
      "support    718.000000    718.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[  0   1   0   2  42]\n",
      " [  0  27   0   1  81]\n",
      " [  0   0   0   0  47]\n",
      " [  0   5   0  26  50]\n",
      " [  0   0   0   3 433]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 69.81%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "              0          1     2          3           4  accuracy   macro avg  \\\n",
      "precision   0.0   0.714286   0.0   0.687500    0.698246  0.698052    0.420006   \n",
      "recall      0.0   0.121951   0.0   0.333333    0.990050  0.698052    0.289067   \n",
      "f1-score    0.0   0.208333   0.0   0.448980    0.818930  0.698052    0.295249   \n",
      "support    19.0  41.000000  14.0  33.000000  201.000000  0.698052  308.000000   \n",
      "\n",
      "           weighted avg  \n",
      "precision      0.624417  \n",
      "recall         0.698052  \n",
      "f1-score       0.610269  \n",
      "support      308.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[  0   0   0   2  17]\n",
      " [  0   5   0   1  35]\n",
      " [  0   0   0   0  14]\n",
      " [  0   2   0  11  20]\n",
      " [  0   0   0   2 199]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "params = {\"criterion\":(\"gini\", \"entropy\"), \n",
    "          \"splitter\":(\"best\", \"random\"), \n",
    "          \"max_depth\":(list(range(1, 20))), \n",
    "          \"min_samples_split\":[2, 3, 4], \n",
    "          \"min_samples_leaf\":list(range(1, 20))\n",
    "          }\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_cv = GridSearchCV(tree_clf, params, scoring=\"accuracy\", n_jobs=-1, verbose=1, cv=5)\n",
    "tree_cv.fit(X_train, y_train)\n",
    "best_params = tree_cv.best_params_\n",
    "print(f'Best_params: {best_params}')\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(**best_params)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(tree_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(tree_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e1733840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Training Accuracy %",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Testing Accuracy %",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "659a7c3b-2440-4002-8a4b-00b38888f66c",
       "rows": [
        [
         "0",
         "Tuned Logistic Regression",
         "100.0",
         "67.20779220779221"
        ],
        [
         "1",
         "Tuned K-nearest neighbors",
         "62.53481894150418",
         "66.23376623376623"
        ],
        [
         "2",
         "Tuned Support Vector Machine",
         "100.0",
         "67.20779220779221"
        ],
        [
         "3",
         "Tuned Decision Tree Classifier",
         "67.68802228412257",
         "69.8051948051948"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy %</th>\n",
       "      <th>Testing Accuracy %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned Logistic Regression</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>67.207792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuned K-nearest neighbors</td>\n",
       "      <td>62.534819</td>\n",
       "      <td>66.233766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tuned Support Vector Machine</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>67.207792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuned Decision Tree Classifier</td>\n",
       "      <td>67.688022</td>\n",
       "      <td>69.805195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model  Training Accuracy %  Testing Accuracy %\n",
       "0       Tuned Logistic Regression           100.000000           67.207792\n",
       "1       Tuned K-nearest neighbors            62.534819           66.233766\n",
       "2    Tuned Support Vector Machine           100.000000           67.207792\n",
       "3  Tuned Decision Tree Classifier            67.688022           69.805195"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = accuracy_score(y_test, tree_clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, tree_clf.predict(X_train)) * 100\n",
    "\n",
    "results_df_2 = pd.DataFrame(\n",
    "    data=[[\"Tuned Decision Tree Classifier\", train_score, test_score]], \n",
    "    columns=['Model', 'Training Accuracy %', 'Testing Accuracy %']\n",
    ")\n",
    "tuning_results_df = pd.concat([tuning_results_df, results_df_2], ignore_index=True)\n",
    "tuning_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c85c615",
   "metadata": {},
   "source": [
    "# 5. Random Forest Classifier Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "dc48b850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "1080 fits failed out of a total of 2160.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "364 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "716 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553\n",
      " 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553\n",
      " 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553\n",
      " 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553\n",
      " 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553\n",
      " 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553\n",
      " 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553\n",
      " 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553\n",
      " 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553\n",
      " 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553\n",
      " 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553\n",
      " 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553\n",
      " 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553\n",
      " 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553\n",
      " 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553\n",
      " 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553\n",
      " 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553\n",
      " 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553\n",
      " 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553\n",
      " 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553\n",
      " 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553\n",
      " 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553\n",
      " 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553\n",
      " 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553\n",
      " 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553\n",
      " 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.65463287 0.65463287 0.65463287 0.65463287 0.65603147 0.65603147\n",
      " 0.65603147 0.65603147 0.65603147 0.65603147 0.65603147 0.65603147\n",
      " 0.6406857  0.6406857  0.6392871  0.6392871  0.6406857  0.6406857\n",
      " 0.6392871  0.6392871  0.6406857  0.6406857  0.6392871  0.6392871\n",
      " 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553\n",
      " 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553 0.60724553]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 500}\n",
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 99.86%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "              0           1     2          3      4  accuracy   macro avg  \\\n",
      "precision   1.0    0.990909   1.0   1.000000    1.0  0.998607    0.998182   \n",
      "recall      1.0    1.000000   1.0   0.987654    1.0  0.998607    0.997531   \n",
      "f1-score    1.0    0.995434   1.0   0.993789    1.0  0.998607    0.997845   \n",
      "support    45.0  109.000000  47.0  81.000000  436.0  0.998607  718.000000   \n",
      "\n",
      "           weighted avg  \n",
      "precision      0.998620  \n",
      "recall         0.998607  \n",
      "f1-score       0.998606  \n",
      "support      718.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[ 45   0   0   0   0]\n",
      " [  0 109   0   0   0]\n",
      " [  0   0  47   0   0]\n",
      " [  0   1   0  80   0]\n",
      " [  0   0   0   0 436]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 69.48%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "              0          1     2          3           4  accuracy   macro avg  \\\n",
      "precision   0.0   0.625000   0.0   0.833333    0.690972  0.694805    0.429861   \n",
      "recall      0.0   0.121951   0.0   0.303030    0.990050  0.694805    0.283006   \n",
      "f1-score    0.0   0.204082   0.0   0.444444    0.813906  0.694805    0.292486   \n",
      "support    19.0  41.000000  14.0  33.000000  201.000000  0.694805  308.000000   \n",
      "\n",
      "           weighted avg  \n",
      "precision      0.623410  \n",
      "recall         0.694805  \n",
      "f1-score       0.605939  \n",
      "support      308.000000  \n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[  0   0   0   0  19]\n",
      " [  0   5   0   1  35]\n",
      " [  0   1   0   0  13]\n",
      " [  0   1   0  10  22]\n",
      " [  0   1   0   1 199]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [500, 900, 1100, 1500]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [2, 3, 5, 10, 15, None]\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "params_grid = {\n",
    "    'n_estimators': n_estimators, \n",
    "    'max_features': max_features,\n",
    "    'max_depth': max_depth, \n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf\n",
    "              }\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "rf_cv = GridSearchCV(rf_clf, params_grid, scoring=\"accuracy\", cv=5, verbose=1, n_jobs=-1)\n",
    "rf_cv.fit(X_train, y_train)\n",
    "best_params = rf_cv.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "rf_clf = RandomForestClassifier(**best_params)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(rf_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "f1bf82f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Training Accuracy %",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Testing Accuracy %",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "67e7eee8-8e5b-4000-807f-dc03d042ea57",
       "rows": [
        [
         "0",
         "Tuned Logistic Regression",
         "100.0",
         "67.20779220779221"
        ],
        [
         "1",
         "Tuned K-nearest neighbors",
         "62.53481894150418",
         "66.23376623376623"
        ],
        [
         "2",
         "Tuned Support Vector Machine",
         "100.0",
         "67.20779220779221"
        ],
        [
         "3",
         "Tuned Decision Tree Classifier",
         "67.68802228412257",
         "69.8051948051948"
        ],
        [
         "4",
         "Tuned Random Forest Classifier",
         "99.86072423398329",
         "69.48051948051948"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Accuracy %</th>\n",
       "      <th>Testing Accuracy %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned Logistic Regression</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>67.207792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuned K-nearest neighbors</td>\n",
       "      <td>62.534819</td>\n",
       "      <td>66.233766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tuned Support Vector Machine</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>67.207792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuned Decision Tree Classifier</td>\n",
       "      <td>67.688022</td>\n",
       "      <td>69.805195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuned Random Forest Classifier</td>\n",
       "      <td>99.860724</td>\n",
       "      <td>69.480519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model  Training Accuracy %  Testing Accuracy %\n",
       "0       Tuned Logistic Regression           100.000000           67.207792\n",
       "1       Tuned K-nearest neighbors            62.534819           66.233766\n",
       "2    Tuned Support Vector Machine           100.000000           67.207792\n",
       "3  Tuned Decision Tree Classifier            67.688022           69.805195\n",
       "4  Tuned Random Forest Classifier            99.860724           69.480519"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = accuracy_score(y_test, rf_clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, rf_clf.predict(X_train)) * 100\n",
    "\n",
    "results_df_2 = pd.DataFrame(\n",
    "    data=[[\"Tuned Random Forest Classifier\", train_score, test_score]], \n",
    "    columns=['Model', 'Training Accuracy %', 'Testing Accuracy %']\n",
    ")\n",
    "tuning_results_df = pd.concat([tuning_results_df, results_df_2], ignore_index=True)\n",
    "tuning_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab111821",
   "metadata": {},
   "source": [
    "# 6. XGBoost Classifier Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "13f90089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 150 candidates, totalling 750 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[200]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      9\u001b[39m xgb_clf = XGBClassifier(use_label_encoder=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     10\u001b[39m xgb_cv = RandomizedSearchCV(\n\u001b[32m     11\u001b[39m     xgb_clf, param_grid, cv=\u001b[32m5\u001b[39m, n_iter=\u001b[32m150\u001b[39m, \n\u001b[32m     12\u001b[39m     scoring=\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m, verbose=\u001b[32m1\u001b[39m\n\u001b[32m     13\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mxgb_cv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m best_params = xgb_cv.best_params_\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest paramters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1951\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1950\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1951\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1952\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1953\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1954\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1955\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    966\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    967\u001b[39m         )\n\u001b[32m    968\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\personal\\Code\\S6\\NLP\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1760\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1763\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1765\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1767\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "param_grid = dict(\n",
    "    n_estimators=stats.randint(10, 1000),\n",
    "    max_depth=stats.randint(1, 10),\n",
    "    learning_rate=stats.uniform(0, 1)\n",
    ")\n",
    "\n",
    "xgb_clf = XGBClassifier(use_label_encoder=False)\n",
    "xgb_cv = RandomizedSearchCV(\n",
    "    xgb_clf, param_grid, cv=5, n_iter=150, \n",
    "    scoring='accuracy', n_jobs=-1, verbose=1\n",
    ")\n",
    "xgb_cv.fit(X_train, y_train)\n",
    "best_params = xgb_cv.best_params_\n",
    "print(f\"Best paramters: {best_params}\")\n",
    "\n",
    "xgb_clf = XGBClassifier(**best_params)\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "print_score(xgb_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(xgb_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38f2d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = accuracy_score(y_test, xgb_clf.predict(X_test)) * 100\n",
    "train_score = accuracy_score(y_train, xgb_clf.predict(X_train)) * 100\n",
    "\n",
    "results_df_2 = pd.DataFrame(\n",
    "    data=[[\"Tuned XGBoost Classifier\", train_score, test_score]], \n",
    "    columns=['Model', 'Training Accuracy %', 'Testing Accuracy %']\n",
    ")\n",
    "tuning_results_df = pd.concat([tuning_results_df, results_df_2], ignore_index=True)\n",
    "tuning_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9045dcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef0d5cd",
   "metadata": {},
   "source": [
    "# 6. Features Importance According to Random Forest and XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "383629fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_imp(df, model):\n",
    "    fi = pd.DataFrame()\n",
    "    fi[\"feature\"] = df.Text\n",
    "    fi[\"importance\"] = model.feature_importances_\n",
    "    return fi.sort_values(by=\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "0ba98b3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'csr_matrix' object has no attribute 'Text'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[204]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mfeature_imp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrf_clf\u001b[49m\u001b[43m)\u001b[49m.plot(kind=\u001b[33m'\u001b[39m\u001b[33mbarh\u001b[39m\u001b[33m'\u001b[39m, figsize=(\u001b[32m12\u001b[39m,\u001b[32m7\u001b[39m), legend=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[203]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mfeature_imp\u001b[39m\u001b[34m(df, model)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfeature_imp\u001b[39m(df, model):\n\u001b[32m      2\u001b[39m     fi = pd.DataFrame()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     fi[\u001b[33m\"\u001b[39m\u001b[33mfeature\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mText\u001b[49m\n\u001b[32m      4\u001b[39m     fi[\u001b[33m\"\u001b[39m\u001b[33mimportance\u001b[39m\u001b[33m\"\u001b[39m] = model.feature_importances_\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fi.sort_values(by=\u001b[33m\"\u001b[39m\u001b[33mimportance\u001b[39m\u001b[33m\"\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'csr_matrix' object has no attribute 'Text'"
     ]
    }
   ],
   "source": [
    "feature_imp(X, rf_clf).plot(kind='barh', figsize=(12,7), legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b11a6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp(X, xgb_clf).plot(kind='barh', figsize=(12,7), legend=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
